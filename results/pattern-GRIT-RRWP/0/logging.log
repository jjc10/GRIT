[*] Run ID 0: seed=0, split_index=0
    Starting now: 2023-11-10 17:47:20.039584
[*] Loaded dataset 'PATTERN' from 'PyG-GNNBenchmarkDataset':
  Data(x=[1664491, 3], edge_index=[2, 85099952], y=[1664491])
  undirected: True
  num graphs: 14000
  avg num_nodes/graph: 118
  num node features: 3
  num edge features: 0
  num classes: 2
Precomputing Positional Encoding statistics: ['RRWP'] for all graphs...
  ...estimated to be undirected: True
Created a temporary directory at /tmp/tmpn4lp0ymq
Writing /tmp/tmpn4lp0ymq/_remote_module_non_scriptable.py
GraphGymModule(
  (model): GritTransformer(
    (encoder): FeatureEncoder(
      (node_encoder): LinearNodeEncoder(
        (encoder): Linear(in_features=3, out_features=64, bias=True)
      )
      (edge_encoder): DummyEdgeEncoder(
        (encoder): Embedding(1, 64)
      )
    )
    (rrwp_abs_encoder): RRWPLinearNodeEncoder(
      (fc): Linear(in_features=21, out_features=64, bias=False)
    )
    (rrwp_rel_encoder): RRWPLinearEdgeEncoder(pad_to_full_graph=True,fill_value=0.0,Linear(in_features=21, out_features=64, bias=False))
    (layers): Sequential(
      (0): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (1): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (2): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (3): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (4): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (5): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (6): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (7): GritTransformerLayer(in_channels=64, out_channels=64, heads=8, residual=True)
      [GritTransformerLayer(
        (act): ReLU()
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=64, out_features=64, bias=True)
          (K): Linear(in_features=64, out_features=64, bias=False)
          (E): Linear(in_features=64, out_features=128, bias=True)
          (V): Linear(in_features=64, out_features=64, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=64, out_features=64, bias=True)
        (O_e): Linear(in_features=64, out_features=64, bias=True)
        (batch_norm1_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=64, out_features=128, bias=True)
        (FFN_h_layer2): Linear(in_features=128, out_features=64, bias=True)
        (batch_norm2_h): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
            (Layer_1): GeneralLayer(
              (layer): Linear(
                (model): Linear(64, 64, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(64, 1, bias=True)
          )
        )
      )
    )
  )
)
accelerator: cuda:0
benchmark: False
best_by_loss: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
cfg_file: configs/GRIT/pattern-GRIT-RRWP.yaml
custom_metrics: []
dataset:
  cache_load: False
  cache_save: False
  dir: ./datasets
  edge_dim: 128
  edge_encoder: True
  edge_encoder_bn: False
  edge_encoder_name: DummyEdge
  edge_encoder_num_types: 0
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: PyG-GNNBenchmarkDataset
  label_column: none
  label_table: none
  location: local
  name: PATTERN
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: LinearNode
  node_encoder_num_types: 0
  pe_transform_on_the_fly: True
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  slic_compactness: 10
  split: [0.8, 0.1, 0.1]
  split_dir: ./splits
  split_index: 0
  split_mode: standard
  task: graph
  task_type: classification
  to_undirected: False
  transductive: False
  transform: none
  tu_simple: True
device: cuda:0
devices: 1
example_arg: example
example_group:
  example_arg: example
gnn:
  act: relu
  agg: mean
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 1
  batchnorm: True
  clear_feature: True
  dim_edge: 64
  dim_inner: 64
  dropout: 0.0
  head: inductive_node
  keep_edge: 0.5
  l2norm: True
  layer_type: generalconv
  layers_mp: 2
  layers_post_mp: 3
  layers_pre_mp: 0
  msg_direction: single
  normalize_adj: False
  residual: False
  self_msg: concat
  skip_every: 1
  stage_type: stack
gpu_mem: False
gt:
  attn:
    O_e: True
    act: relu
    clamp: 5.0
    deg_scaler: True
    edge_enhance: True
    full_attn: True
    fwl: False
    norm_e: True
    sparse: False
    use: True
    use_bias: False
  attn_dropout: 0.2
  batch_norm: True
  bigbird:
    add_cross_attention: False
    attention_type: block_sparse
    block_size: 3
    chunk_size_feed_forward: 0
    hidden_act: relu
    is_decoder: False
    layer_norm_eps: 1e-06
    max_position_embeddings: 128
    num_random_blocks: 3
    use_bias: False
  bn_momentum: 0.1
  bn_no_runner: False
  dim_hidden: 64
  dropout: 0.0
  full_graph: True
  gamma: 1e-05
  layer_norm: False
  layer_type: GritTransformer
  layers: 8
  n_heads: 8
  pna_degrees: []
  residual: True
  update_e: True
mem:
  inplace: False
metric_agg: argmax
metric_best: accuracy-SBM
mlflow:
  name: pattern-GRIT-RRWP
  project: Exp
  use: False
model:
  edge_decoding: dot
  graph_pooling: add
  loss_fun: weighted_cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: GritTransformer
name_tag: 
num_threads: 6
num_workers: 0
optim:
  base_lr: 0.0005
  batch_accumulation: 1
  clip_grad_norm: True
  early_stop_by_lr: False
  early_stop_by_perf: False
  lr_decay: 0.1
  max_epoch: 100
  min_lr: 0.0
  min_lr_mode: threshold
  momentum: 0.9
  num_cycles: 0.5
  num_warmup_epochs: 5
  optimizer: adamW
  reduce_factor: 0.5
  schedule_patience: 10
  scheduler: cosine_with_warmup
  steps: [30, 60, 90]
  stop_patience: 100
  weight_decay: 1e-05
out_dir: results/pattern-GRIT-RRWP
posenc_ElstaticSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: range(10)
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_EquivStableLapPE:
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  raw_norm_type: none
posenc_HKdiagSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_LapPE:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_RRWP:
  add_identity: True
  add_node_attr: False
  dim_pe: 16
  enable: True
  ksteps: 21
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
  spd: False
posenc_RWSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_SignNet:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  phi_hidden_dim: 64
  phi_out_dim: 4
  post_layers: 0
  raw_norm_type: none
pretrained:
  dir: 
  freeze_main: False
  reset_prediction_head: True
print: both
round: 5
run_dir: results/pattern-GRIT-RRWP/0
run_id: 0
run_multiple_splits: []
seed: 0
share:
  dim_in: 3
  dim_out: 2
  num_splits: 3
tensorboard_agg: True
tensorboard_each_run: True
train:
  auto_resume: False
  batch_size: 12
  ckpt_best: True
  ckpt_clean: True
  ckpt_period: 1
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  mode: custom
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
  skip_train_eval: False
  walk_length: 4
val:
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
wandb:
  entity: gtransformers
  name: 
  project: PATTERN
  use: False
work_dir: /home/joud/code/relu_analysis/GRIT
Num parameters: 384641
Start from epoch 0
train: {'epoch': 0, 'time_epoch': 424.34185, 'eta': 42009.84306, 'eta_hours': 11.6694, 'loss': 0.20187704, 'lr': 0.0, 'params': 384641, 'time_iter': 0.5088, 'accuracy': 0.82348, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.54785, 'accuracy-SBM': 0.5}
...computing epoch stats took: 1.01s
val: {'epoch': 0, 'time_epoch': 29.35845, 'loss': 0.19882266, 'lr': 0, 'params': 384641, 'time_iter': 0.1758, 'accuracy': 0.82298, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.55529, 'accuracy-SBM': 0.5}
...computing epoch stats took: 0.18s
test: {'epoch': 0, 'time_epoch': 29.80797, 'loss': 0.1982096, 'lr': 0, 'params': 384641, 'time_iter': 0.17849, 'accuracy': 0.82378, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.55395, 'accuracy-SBM': 0.5}
...computing epoch stats took: 0.18s
> Epoch 0: took 484.9s (avg 484.9s) | Best so far: epoch 0	train_loss: 0.2019 train_accuracy-SBM: 0.5000	val_loss: 0.1988 val_accuracy-SBM: 0.5000	test_loss: 0.1982 test_accuracy-SBM: 0.5000
-----------------------------------------------------------
train: {'epoch': 1, 'time_epoch': 432.44715, 'eta': 41982.66108, 'eta_hours': 11.66185, 'loss': 0.14811036, 'lr': 0.0001, 'params': 384641, 'time_iter': 0.51852, 'accuracy': 0.85125, 'precision': 0.55185, 'recall': 0.83722, 'f1': 0.66522, 'auc': 0.88862, 'accuracy-SBM': 0.84574}
...computing epoch stats took: 1.11s
val: {'epoch': 1, 'time_epoch': 29.53008, 'loss': 0.13254138, 'lr': 0, 'params': 384641, 'time_iter': 0.17683, 'accuracy': 0.88976, 'precision': 0.65402, 'recall': 0.80102, 'f1': 0.7201, 'auc': 0.92053, 'accuracy-SBM': 0.85494}
...computing epoch stats took: 0.21s
test: {'epoch': 1, 'time_epoch': 29.87308, 'loss': 0.1315498, 'lr': 0, 'params': 384641, 'time_iter': 0.17888, 'accuracy': 0.89207, 'precision': 0.65928, 'recall': 0.802, 'f1': 0.72367, 'auc': 0.92138, 'accuracy-SBM': 0.85667}
...computing epoch stats took: 0.20s
> Epoch 1: took 493.4s (avg 489.1s) | Best so far: epoch 1	train_loss: 0.1481 train_accuracy-SBM: 0.8457	val_loss: 0.1325 val_accuracy-SBM: 0.8549	test_loss: 0.1315 test_accuracy-SBM: 0.8567
-----------------------------------------------------------
train: {'epoch': 2, 'time_epoch': 431.20873, 'eta': 41645.26008, 'eta_hours': 11.56813, 'loss': 0.11824927, 'lr': 0.0002, 'params': 384641, 'time_iter': 0.51704, 'accuracy': 0.85924, 'precision': 0.56662, 'recall': 0.86147, 'f1': 0.68361, 'auc': 0.91632, 'accuracy-SBM': 0.86012}
...computing epoch stats took: 1.13s
val: {'epoch': 2, 'time_epoch': 29.72698, 'loss': 0.11188413, 'lr': 0, 'params': 384641, 'time_iter': 0.17801, 'accuracy': 0.8225, 'precision': 0.49926, 'recall': 0.91139, 'f1': 0.64512, 'auc': 0.93797, 'accuracy-SBM': 0.85738}
...computing epoch stats took: 0.21s
test: {'epoch': 2, 'time_epoch': 30.04114, 'loss': 0.1106657, 'lr': 0, 'params': 384641, 'time_iter': 0.17989, 'accuracy': 0.82564, 'precision': 0.50291, 'recall': 0.91096, 'f1': 0.64805, 'auc': 0.93873, 'accuracy-SBM': 0.85917}
...computing epoch stats took: 0.21s
> Epoch 2: took 492.6s (avg 490.3s) | Best so far: epoch 2	train_loss: 0.1182 train_accuracy-SBM: 0.8601	val_loss: 0.1119 val_accuracy-SBM: 0.8574	test_loss: 0.1107 test_accuracy-SBM: 0.8592
-----------------------------------------------------------
train: {'epoch': 3, 'time_epoch': 431.48903, 'eta': 41267.68223, 'eta_hours': 11.46325, 'loss': 0.10287956, 'lr': 0.0003, 'params': 384641, 'time_iter': 0.51737, 'accuracy': 0.86034, 'precision': 0.56878, 'recall': 0.86343, 'f1': 0.6858, 'auc': 0.92974, 'accuracy-SBM': 0.86156}
val: {'epoch': 3, 'time_epoch': 29.57331, 'loss': 0.1011737, 'lr': 0, 'params': 384641, 'time_iter': 0.17709, 'accuracy': 0.87818, 'precision': 0.61528, 'recall': 0.83213, 'f1': 0.70746, 'auc': 0.9384, 'accuracy-SBM': 0.86011}
test: {'epoch': 3, 'time_epoch': 29.9625, 'loss': 0.10027277, 'lr': 0, 'params': 384641, 'time_iter': 0.17942, 'accuracy': 0.88034, 'precision': 0.61925, 'recall': 0.83342, 'f1': 0.71055, 'auc': 0.93913, 'accuracy-SBM': 0.8619}
> Epoch 3: took 492.6s (avg 490.9s) | Best so far: epoch 3	train_loss: 0.1029 train_accuracy-SBM: 0.8616	val_loss: 0.1012 val_accuracy-SBM: 0.8601	test_loss: 0.1003 test_accuracy-SBM: 0.8619
-----------------------------------------------------------
train: {'epoch': 4, 'time_epoch': 430.80704, 'eta': 40855.58226, 'eta_hours': 11.34877, 'loss': 0.09611854, 'lr': 0.0004, 'params': 384641, 'time_iter': 0.51656, 'accuracy': 0.86078, 'precision': 0.56956, 'recall': 0.86495, 'f1': 0.68684, 'auc': 0.93558, 'accuracy-SBM': 0.86242}
val: {'epoch': 4, 'time_epoch': 29.69007, 'loss': 0.0976694, 'lr': 0, 'params': 384641, 'time_iter': 0.17778, 'accuracy': 0.82273, 'precision': 0.49961, 'recall': 0.91172, 'f1': 0.6455, 'auc': 0.93939, 'accuracy-SBM': 0.85765}
test: {'epoch': 4, 'time_epoch': 30.04261, 'loss': 0.0963816, 'lr': 0, 'params': 384641, 'time_iter': 0.1799, 'accuracy': 0.82521, 'precision': 0.50224, 'recall': 0.90958, 'f1': 0.64715, 'auc': 0.9401, 'accuracy-SBM': 0.85837}
> Epoch 4: took 492.1s (avg 491.1s) | Best so far: epoch 3	train_loss: 0.1029 train_accuracy-SBM: 0.8616	val_loss: 0.1012 val_accuracy-SBM: 0.8601	test_loss: 0.1003 test_accuracy-SBM: 0.8619
-----------------------------------------------------------
train: {'epoch': 5, 'time_epoch': 435.66806, 'eta': 40513.40245, 'eta_hours': 11.25372, 'loss': 0.09309934, 'lr': 0.0005, 'params': 384641, 'time_iter': 0.52238, 'accuracy': 0.8615, 'precision': 0.57107, 'recall': 0.86533, 'f1': 0.68806, 'auc': 0.93802, 'accuracy-SBM': 0.86301}
val: {'epoch': 5, 'time_epoch': 29.69575, 'loss': 0.09645006, 'lr': 0, 'params': 384641, 'time_iter': 0.17782, 'accuracy': 0.81433, 'precision': 0.48702, 'recall': 0.9166, 'f1': 0.63607, 'auc': 0.93896, 'accuracy-SBM': 0.85447}
test: {'epoch': 5, 'time_epoch': 29.96116, 'loss': 0.09525163, 'lr': 0, 'params': 384641, 'time_iter': 0.17941, 'accuracy': 0.81681, 'precision': 0.48942, 'recall': 0.9151, 'f1': 0.63775, 'auc': 0.93952, 'accuracy-SBM': 0.85544}
> Epoch 5: took 496.9s (avg 492.1s) | Best so far: epoch 3	train_loss: 0.1029 train_accuracy-SBM: 0.8616	val_loss: 0.1012 val_accuracy-SBM: 0.8601	test_loss: 0.1003 test_accuracy-SBM: 0.8619
-----------------------------------------------------------
train: {'epoch': 6, 'time_epoch': 435.84975, 'eta': 40146.92569, 'eta_hours': 11.15192, 'loss': 0.09155015, 'lr': 0.00049986, 'params': 384641, 'time_iter': 0.5226, 'accuracy': 0.86271, 'precision': 0.57373, 'recall': 0.86466, 'f1': 0.68977, 'auc': 0.93932, 'accuracy-SBM': 0.86348}
val: {'epoch': 6, 'time_epoch': 30.1417, 'loss': 0.09772777, 'lr': 0, 'params': 384641, 'time_iter': 0.18049, 'accuracy': 0.88932, 'precision': 0.65295, 'recall': 0.79995, 'f1': 0.71902, 'auc': 0.93885, 'accuracy-SBM': 0.85425}
test: {'epoch': 6, 'time_epoch': 30.51997, 'loss': 0.09657918, 'lr': 0, 'params': 384641, 'time_iter': 0.18275, 'accuracy': 0.89175, 'precision': 0.65846, 'recall': 0.80143, 'f1': 0.72294, 'auc': 0.93991, 'accuracy-SBM': 0.85625}
> Epoch 6: took 498.1s (avg 492.9s) | Best so far: epoch 3	train_loss: 0.1029 train_accuracy-SBM: 0.8616	val_loss: 0.1012 val_accuracy-SBM: 0.8601	test_loss: 0.1003 test_accuracy-SBM: 0.8619
-----------------------------------------------------------
train: {'epoch': 7, 'time_epoch': 440.1113, 'eta': 39812.11342, 'eta_hours': 11.05892, 'loss': 0.09089363, 'lr': 0.00049945, 'params': 384641, 'time_iter': 0.52771, 'accuracy': 0.86212, 'precision': 0.57229, 'recall': 0.86643, 'f1': 0.68929, 'auc': 0.93979, 'accuracy-SBM': 0.86381}
val: {'epoch': 7, 'time_epoch': 30.94945, 'loss': 0.09190668, 'lr': 0, 'params': 384641, 'time_iter': 0.18533, 'accuracy': 0.84243, 'precision': 0.53296, 'recall': 0.88838, 'f1': 0.66623, 'auc': 0.93922, 'accuracy-SBM': 0.86046}
test: {'epoch': 7, 'time_epoch': 30.36098, 'loss': 0.09090532, 'lr': 0, 'params': 384641, 'time_iter': 0.1818, 'accuracy': 0.84484, 'precision': 0.53603, 'recall': 0.88902, 'f1': 0.66881, 'auc': 0.93993, 'accuracy-SBM': 0.8622}
> Epoch 7: took 503.0s (avg 494.2s) | Best so far: epoch 7	train_loss: 0.0909 train_accuracy-SBM: 0.8638	val_loss: 0.0919 val_accuracy-SBM: 0.8605	test_loss: 0.0909 test_accuracy-SBM: 0.8622
-----------------------------------------------------------
train: {'epoch': 8, 'time_epoch': 433.21626, 'eta': 39384.18487, 'eta_hours': 10.94005, 'loss': 0.09041164, 'lr': 0.00049877, 'params': 384641, 'time_iter': 0.51944, 'accuracy': 0.86277, 'precision': 0.5737, 'recall': 0.86631, 'f1': 0.69027, 'auc': 0.94034, 'accuracy-SBM': 0.86416}
val: {'epoch': 8, 'time_epoch': 29.90289, 'loss': 0.0943187, 'lr': 0, 'params': 384641, 'time_iter': 0.17906, 'accuracy': 0.87287, 'precision': 0.59962, 'recall': 0.84819, 'f1': 0.70256, 'auc': 0.93986, 'accuracy-SBM': 0.86318}
test: {'epoch': 8, 'time_epoch': 30.33347, 'loss': 0.09316998, 'lr': 0, 'params': 384641, 'time_iter': 0.18164, 'accuracy': 0.8754, 'precision': 0.60445, 'recall': 0.84752, 'f1': 0.70564, 'auc': 0.94058, 'accuracy-SBM': 0.86444}
> Epoch 8: took 495.0s (avg 494.3s) | Best so far: epoch 8	train_loss: 0.0904 train_accuracy-SBM: 0.8642	val_loss: 0.0943 val_accuracy-SBM: 0.8632	test_loss: 0.0932 test_accuracy-SBM: 0.8644
-----------------------------------------------------------
train: {'epoch': 9, 'time_epoch': 438.67816, 'eta': 39004.35595, 'eta_hours': 10.83454, 'loss': 0.09017793, 'lr': 0.00049782, 'params': 384641, 'time_iter': 0.52599, 'accuracy': 0.8624, 'precision': 0.57276, 'recall': 0.86775, 'f1': 0.69005, 'auc': 0.94049, 'accuracy-SBM': 0.8645}
val: {'epoch': 9, 'time_epoch': 29.60038, 'loss': 0.09583258, 'lr': 0, 'params': 384641, 'time_iter': 0.17725, 'accuracy': 0.88954, 'precision': 0.65213, 'recall': 0.80598, 'f1': 0.72094, 'auc': 0.94071, 'accuracy-SBM': 0.85675}
test: {'epoch': 9, 'time_epoch': 29.93412, 'loss': 0.09488274, 'lr': 0, 'params': 384641, 'time_iter': 0.17925, 'accuracy': 0.89227, 'precision': 0.65876, 'recall': 0.80641, 'f1': 0.72514, 'auc': 0.94154, 'accuracy-SBM': 0.85853}
> Epoch 9: took 499.7s (avg 494.8s) | Best so far: epoch 8	train_loss: 0.0904 train_accuracy-SBM: 0.8642	val_loss: 0.0943 val_accuracy-SBM: 0.8632	test_loss: 0.0932 test_accuracy-SBM: 0.8644
-----------------------------------------------------------
train: {'epoch': 10, 'time_epoch': 429.3685, 'eta': 38538.50348, 'eta_hours': 10.70514, 'loss': 0.09004315, 'lr': 0.00049659, 'params': 384641, 'time_iter': 0.51483, 'accuracy': 0.86283, 'precision': 0.57376, 'recall': 0.86704, 'f1': 0.69055, 'auc': 0.94059, 'accuracy-SBM': 0.86449}
val: {'epoch': 10, 'time_epoch': 29.42228, 'loss': 0.09377256, 'lr': 0, 'params': 384641, 'time_iter': 0.17618, 'accuracy': 0.88357, 'precision': 0.63026, 'recall': 0.82808, 'f1': 0.71575, 'auc': 0.94105, 'accuracy-SBM': 0.86179}
test: {'epoch': 10, 'time_epoch': 29.59005, 'loss': 0.09266453, 'lr': 0, 'params': 384641, 'time_iter': 0.17719, 'accuracy': 0.88607, 'precision': 0.63572, 'recall': 0.82787, 'f1': 0.71918, 'auc': 0.94204, 'accuracy-SBM': 0.8632}
> Epoch 10: took 489.9s (avg 494.4s) | Best so far: epoch 8	train_loss: 0.0904 train_accuracy-SBM: 0.8642	val_loss: 0.0943 val_accuracy-SBM: 0.8632	test_loss: 0.0932 test_accuracy-SBM: 0.8644
-----------------------------------------------------------
train: {'epoch': 11, 'time_epoch': 428.14278, 'eta': 38069.74311, 'eta_hours': 10.57493, 'loss': 0.08993601, 'lr': 0.00049509, 'params': 384641, 'time_iter': 0.51336, 'accuracy': 0.86238, 'precision': 0.57278, 'recall': 0.86709, 'f1': 0.68986, 'auc': 0.94073, 'accuracy-SBM': 0.86423}
val: {'epoch': 11, 'time_epoch': 29.27979, 'loss': 0.09022945, 'lr': 0, 'params': 384641, 'time_iter': 0.17533, 'accuracy': 0.87116, 'precision': 0.59437, 'recall': 0.85722, 'f1': 0.70199, 'auc': 0.94185, 'accuracy-SBM': 0.86569}
test: {'epoch': 11, 'time_epoch': 29.28664, 'loss': 0.08913813, 'lr': 0, 'params': 384641, 'time_iter': 0.17537, 'accuracy': 0.87355, 'precision': 0.59836, 'recall': 0.85905, 'f1': 0.70539, 'auc': 0.94271, 'accuracy-SBM': 0.86785}
> Epoch 11: took 488.2s (avg 493.9s) | Best so far: epoch 11	train_loss: 0.0899 train_accuracy-SBM: 0.8642	val_loss: 0.0902 val_accuracy-SBM: 0.8657	test_loss: 0.0891 test_accuracy-SBM: 0.8679
-----------------------------------------------------------
train: {'epoch': 12, 'time_epoch': 422.89289, 'eta': 37572.09771, 'eta_hours': 10.43669, 'loss': 0.08983965, 'lr': 0.00049333, 'params': 384641, 'time_iter': 0.50707, 'accuracy': 0.86248, 'precision': 0.57286, 'recall': 0.86847, 'f1': 0.69035, 'auc': 0.9408, 'accuracy-SBM': 0.86483}
val: {'epoch': 12, 'time_epoch': 29.73208, 'loss': 0.09256848, 'lr': 0, 'params': 384641, 'time_iter': 0.17804, 'accuracy': 0.87718, 'precision': 0.61054, 'recall': 0.8455, 'f1': 0.70906, 'auc': 0.94137, 'accuracy-SBM': 0.86474}
test: {'epoch': 12, 'time_epoch': 30.25584, 'loss': 0.09147773, 'lr': 0, 'params': 384641, 'time_iter': 0.18117, 'accuracy': 0.87948, 'precision': 0.61516, 'recall': 0.84416, 'f1': 0.71169, 'auc': 0.94224, 'accuracy-SBM': 0.8656}
> Epoch 12: took 484.4s (avg 493.1s) | Best so far: epoch 11	train_loss: 0.0899 train_accuracy-SBM: 0.8642	val_loss: 0.0902 val_accuracy-SBM: 0.8657	test_loss: 0.0891 test_accuracy-SBM: 0.8679
-----------------------------------------------------------
train: {'epoch': 13, 'time_epoch': 428.52366, 'eta': 37119.72028, 'eta_hours': 10.31103, 'loss': 0.08973536, 'lr': 0.0004913, 'params': 384641, 'time_iter': 0.51382, 'accuracy': 0.86299, 'precision': 0.57402, 'recall': 0.86781, 'f1': 0.69098, 'auc': 0.94094, 'accuracy-SBM': 0.86488}
val: {'epoch': 13, 'time_epoch': 29.10286, 'loss': 0.09117244, 'lr': 0, 'params': 384641, 'time_iter': 0.17427, 'accuracy': 0.86257, 'precision': 0.57357, 'recall': 0.87192, 'f1': 0.69195, 'auc': 0.94195, 'accuracy-SBM': 0.86624}
test: {'epoch': 13, 'time_epoch': 29.47194, 'loss': 0.08997151, 'lr': 0, 'params': 384641, 'time_iter': 0.17648, 'accuracy': 0.86503, 'precision': 0.57758, 'recall': 0.87134, 'f1': 0.69468, 'auc': 0.94282, 'accuracy-SBM': 0.86751}
> Epoch 13: took 488.7s (avg 492.8s) | Best so far: epoch 13	train_loss: 0.0897 train_accuracy-SBM: 0.8649	val_loss: 0.0912 val_accuracy-SBM: 0.8662	test_loss: 0.0900 test_accuracy-SBM: 0.8675
-----------------------------------------------------------
train: {'epoch': 14, 'time_epoch': 423.12906, 'eta': 36639.95392, 'eta_hours': 10.17776, 'loss': 0.08964405, 'lr': 0.00048901, 'params': 384641, 'time_iter': 0.50735, 'accuracy': 0.86391, 'precision': 0.57608, 'recall': 0.86704, 'f1': 0.69223, 'auc': 0.94104, 'accuracy-SBM': 0.86514}
val: {'epoch': 14, 'time_epoch': 29.23045, 'loss': 0.09433779, 'lr': 0, 'params': 384641, 'time_iter': 0.17503, 'accuracy': 0.89024, 'precision': 0.65247, 'recall': 0.81296, 'f1': 0.72393, 'auc': 0.94202, 'accuracy-SBM': 0.85991}
test: {'epoch': 14, 'time_epoch': 29.44487, 'loss': 0.09336629, 'lr': 0, 'params': 384641, 'time_iter': 0.17632, 'accuracy': 0.89191, 'precision': 0.65567, 'recall': 0.81417, 'f1': 0.72638, 'auc': 0.94287, 'accuracy-SBM': 0.86136}
> Epoch 14: took 483.4s (avg 492.2s) | Best so far: epoch 13	train_loss: 0.0897 train_accuracy-SBM: 0.8649	val_loss: 0.0912 val_accuracy-SBM: 0.8662	test_loss: 0.0900 test_accuracy-SBM: 0.8675
-----------------------------------------------------------
train: {'epoch': 15, 'time_epoch': 422.7374, 'eta': 36165.21103, 'eta_hours': 10.04589, 'loss': 0.08953878, 'lr': 0.00048645, 'params': 384641, 'time_iter': 0.50688, 'accuracy': 0.86363, 'precision': 0.57544, 'recall': 0.86737, 'f1': 0.69187, 'auc': 0.94116, 'accuracy-SBM': 0.8651}
val: {'epoch': 15, 'time_epoch': 29.15566, 'loss': 0.09058532, 'lr': 0, 'params': 384641, 'time_iter': 0.17458, 'accuracy': 0.86125, 'precision': 0.57088, 'recall': 0.87075, 'f1': 0.68963, 'auc': 0.94127, 'accuracy-SBM': 0.86498}
test: {'epoch': 15, 'time_epoch': 29.46082, 'loss': 0.08960752, 'lr': 0, 'params': 384641, 'time_iter': 0.17641, 'accuracy': 0.86412, 'precision': 0.57549, 'recall': 0.87249, 'f1': 0.69353, 'auc': 0.94191, 'accuracy-SBM': 0.86741}
> Epoch 15: took 482.9s (avg 491.6s) | Best so far: epoch 13	train_loss: 0.0897 train_accuracy-SBM: 0.8649	val_loss: 0.0912 val_accuracy-SBM: 0.8662	test_loss: 0.0900 test_accuracy-SBM: 0.8675
-----------------------------------------------------------
train: {'epoch': 16, 'time_epoch': 422.23801, 'eta': 35694.1482, 'eta_hours': 9.91504, 'loss': 0.08946811, 'lr': 0.00048364, 'params': 384641, 'time_iter': 0.50628, 'accuracy': 0.86443, 'precision': 0.57729, 'recall': 0.86639, 'f1': 0.69289, 'auc': 0.9413, 'accuracy-SBM': 0.8652}
val: {'epoch': 16, 'time_epoch': 29.12014, 'loss': 0.09005106, 'lr': 0, 'params': 384641, 'time_iter': 0.17437, 'accuracy': 0.86182, 'precision': 0.57183, 'recall': 0.87325, 'f1': 0.69111, 'auc': 0.94207, 'accuracy-SBM': 0.8663}
test: {'epoch': 16, 'time_epoch': 29.33659, 'loss': 0.08889101, 'lr': 0, 'params': 384641, 'time_iter': 0.17567, 'accuracy': 0.86455, 'precision': 0.57639, 'recall': 0.87292, 'f1': 0.69432, 'auc': 0.94285, 'accuracy-SBM': 0.86784}
> Epoch 16: took 482.2s (avg 491.1s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 17, 'time_epoch': 422.63034, 'eta': 35230.29767, 'eta_hours': 9.78619, 'loss': 0.08943638, 'lr': 0.00048057, 'params': 384641, 'time_iter': 0.50675, 'accuracy': 0.86362, 'precision': 0.57528, 'recall': 0.8687, 'f1': 0.69218, 'auc': 0.94133, 'accuracy-SBM': 0.86561}
val: {'epoch': 17, 'time_epoch': 29.01956, 'loss': 0.09101198, 'lr': 0, 'params': 384641, 'time_iter': 0.17377, 'accuracy': 0.85508, 'precision': 0.55731, 'recall': 0.88161, 'f1': 0.68292, 'auc': 0.94175, 'accuracy-SBM': 0.86549}
test: {'epoch': 17, 'time_epoch': 29.43341, 'loss': 0.08995337, 'lr': 0, 'params': 384641, 'time_iter': 0.17625, 'accuracy': 0.85795, 'precision': 0.5618, 'recall': 0.88152, 'f1': 0.68624, 'auc': 0.94242, 'accuracy-SBM': 0.86721}
> Epoch 17: took 482.6s (avg 490.6s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 18, 'time_epoch': 422.36881, 'eta': 34769.67113, 'eta_hours': 9.65824, 'loss': 0.08941602, 'lr': 0.00047725, 'params': 384641, 'time_iter': 0.50644, 'accuracy': 0.86365, 'precision': 0.5754, 'recall': 0.86828, 'f1': 0.69214, 'auc': 0.94132, 'accuracy-SBM': 0.86547}
val: {'epoch': 18, 'time_epoch': 29.21758, 'loss': 0.08968829, 'lr': 0, 'params': 384641, 'time_iter': 0.17496, 'accuracy': 0.86723, 'precision': 0.58459, 'recall': 0.86372, 'f1': 0.69725, 'auc': 0.94214, 'accuracy-SBM': 0.86585}
test: {'epoch': 18, 'time_epoch': 29.38653, 'loss': 0.08866867, 'lr': 0, 'params': 384641, 'time_iter': 0.17597, 'accuracy': 0.86987, 'precision': 0.58898, 'recall': 0.8656, 'f1': 0.70099, 'auc': 0.94282, 'accuracy-SBM': 0.86819}
> Epoch 18: took 482.5s (avg 490.2s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 19, 'time_epoch': 422.969, 'eta': 34315.27115, 'eta_hours': 9.53202, 'loss': 0.08933138, 'lr': 0.00047368, 'params': 384641, 'time_iter': 0.50716, 'accuracy': 0.86439, 'precision': 0.57713, 'recall': 0.86706, 'f1': 0.69299, 'auc': 0.94147, 'accuracy-SBM': 0.86544}
val: {'epoch': 19, 'time_epoch': 29.16787, 'loss': 0.09469745, 'lr': 0, 'params': 384641, 'time_iter': 0.17466, 'accuracy': 0.88868, 'precision': 0.64802, 'recall': 0.81248, 'f1': 0.72099, 'auc': 0.94117, 'accuracy-SBM': 0.85878}
test: {'epoch': 19, 'time_epoch': 29.44064, 'loss': 0.09368427, 'lr': 0, 'params': 384641, 'time_iter': 0.17629, 'accuracy': 0.89085, 'precision': 0.65254, 'recall': 0.81408, 'f1': 0.72441, 'auc': 0.94197, 'accuracy-SBM': 0.86068}
> Epoch 19: took 483.1s (avg 489.8s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 20, 'time_epoch': 422.77971, 'eta': 33863.15248, 'eta_hours': 9.40643, 'loss': 0.08927617, 'lr': 0.00046987, 'params': 384641, 'time_iter': 0.50693, 'accuracy': 0.86294, 'precision': 0.57377, 'recall': 0.86925, 'f1': 0.69125, 'auc': 0.94154, 'accuracy-SBM': 0.86542}
val: {'epoch': 20, 'time_epoch': 29.08175, 'loss': 0.09340595, 'lr': 0, 'params': 384641, 'time_iter': 0.17414, 'accuracy': 0.89049, 'precision': 0.65336, 'recall': 0.81232, 'f1': 0.72422, 'auc': 0.94167, 'accuracy-SBM': 0.85981}
test: {'epoch': 20, 'time_epoch': 29.4013, 'loss': 0.0923723, 'lr': 0, 'params': 384641, 'time_iter': 0.17606, 'accuracy': 0.89234, 'precision': 0.65716, 'recall': 0.81339, 'f1': 0.72697, 'auc': 0.94251, 'accuracy-SBM': 0.86131}
> Epoch 20: took 482.8s (avg 489.5s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 21, 'time_epoch': 422.53681, 'eta': 33412.83979, 'eta_hours': 9.28134, 'loss': 0.08922658, 'lr': 0.00046581, 'params': 384641, 'time_iter': 0.50664, 'accuracy': 0.86395, 'precision': 0.5761, 'recall': 0.86783, 'f1': 0.69249, 'auc': 0.9416, 'accuracy-SBM': 0.86547}
val: {'epoch': 21, 'time_epoch': 29.13926, 'loss': 0.09067424, 'lr': 0, 'params': 384641, 'time_iter': 0.17449, 'accuracy': 0.85193, 'precision': 0.55077, 'recall': 0.88718, 'f1': 0.67962, 'auc': 0.94239, 'accuracy-SBM': 0.86577}
test: {'epoch': 21, 'time_epoch': 29.49592, 'loss': 0.08956129, 'lr': 0, 'params': 384641, 'time_iter': 0.17662, 'accuracy': 0.85456, 'precision': 0.55461, 'recall': 0.88695, 'f1': 0.68247, 'auc': 0.94309, 'accuracy-SBM': 0.86729}
> Epoch 21: took 482.7s (avg 489.2s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 22, 'time_epoch': 423.08324, 'eta': 32966.77178, 'eta_hours': 9.15744, 'loss': 0.08908546, 'lr': 0.00046152, 'params': 384641, 'time_iter': 0.50729, 'accuracy': 0.86489, 'precision': 0.57822, 'recall': 0.86712, 'f1': 0.6938, 'auc': 0.94181, 'accuracy-SBM': 0.86577}
val: {'epoch': 22, 'time_epoch': 29.14147, 'loss': 0.09171041, 'lr': 0, 'params': 384641, 'time_iter': 0.1745, 'accuracy': 0.87344, 'precision': 0.60014, 'recall': 0.85414, 'f1': 0.70496, 'auc': 0.94219, 'accuracy-SBM': 0.86587}
test: {'epoch': 22, 'time_epoch': 29.48942, 'loss': 0.09059748, 'lr': 0, 'params': 384641, 'time_iter': 0.17658, 'accuracy': 0.87617, 'precision': 0.60542, 'recall': 0.85369, 'f1': 0.70844, 'auc': 0.94306, 'accuracy-SBM': 0.86734}
> Epoch 22: took 483.2s (avg 488.9s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 23, 'time_epoch': 422.84078, 'eta': 32521.85135, 'eta_hours': 9.03385, 'loss': 0.08918926, 'lr': 0.000457, 'params': 384641, 'time_iter': 0.507, 'accuracy': 0.86381, 'precision': 0.57576, 'recall': 0.86819, 'f1': 0.69237, 'auc': 0.94163, 'accuracy-SBM': 0.86553}
val: {'epoch': 23, 'time_epoch': 29.08987, 'loss': 0.09106517, 'lr': 0, 'params': 384641, 'time_iter': 0.17419, 'accuracy': 0.87369, 'precision': 0.60078, 'recall': 0.85388, 'f1': 0.70531, 'auc': 0.94217, 'accuracy-SBM': 0.86592}
test: {'epoch': 23, 'time_epoch': 29.4573, 'loss': 0.08987903, 'lr': 0, 'params': 384641, 'time_iter': 0.17639, 'accuracy': 0.877, 'precision': 0.60738, 'recall': 0.85412, 'f1': 0.70992, 'auc': 0.94306, 'accuracy-SBM': 0.86801}
> Epoch 23: took 482.9s (avg 488.7s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 24, 'time_epoch': 422.20732, 'eta': 32076.79693, 'eta_hours': 8.91022, 'loss': 0.08906612, 'lr': 0.00045225, 'params': 384641, 'time_iter': 0.50624, 'accuracy': 0.86368, 'precision': 0.57541, 'recall': 0.86876, 'f1': 0.69229, 'auc': 0.94183, 'accuracy-SBM': 0.86567}
val: {'epoch': 24, 'time_epoch': 29.06731, 'loss': 0.09367851, 'lr': 0, 'params': 384641, 'time_iter': 0.17406, 'accuracy': 0.88617, 'precision': 0.6376, 'recall': 0.82704, 'f1': 0.72006, 'auc': 0.9421, 'accuracy-SBM': 0.86296}
test: {'epoch': 24, 'time_epoch': 29.3416, 'loss': 0.09254602, 'lr': 0, 'params': 384641, 'time_iter': 0.1757, 'accuracy': 0.88842, 'precision': 0.64219, 'recall': 0.82842, 'f1': 0.72351, 'auc': 0.9431, 'accuracy-SBM': 0.86484}
> Epoch 24: took 482.2s (avg 488.4s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 25, 'time_epoch': 422.07157, 'eta': 31633.1136, 'eta_hours': 8.78698, 'loss': 0.08906706, 'lr': 0.00044729, 'params': 384641, 'time_iter': 0.50608, 'accuracy': 0.86302, 'precision': 0.57388, 'recall': 0.8699, 'f1': 0.69154, 'auc': 0.9418, 'accuracy-SBM': 0.86572}
val: {'epoch': 25, 'time_epoch': 29.27231, 'loss': 0.09030856, 'lr': 0, 'params': 384641, 'time_iter': 0.17528, 'accuracy': 0.87383, 'precision': 0.60106, 'recall': 0.85424, 'f1': 0.70563, 'auc': 0.94245, 'accuracy-SBM': 0.86614}
test: {'epoch': 25, 'time_epoch': 29.38814, 'loss': 0.08913462, 'lr': 0, 'params': 384641, 'time_iter': 0.17598, 'accuracy': 0.87677, 'precision': 0.6066, 'recall': 0.85553, 'f1': 0.70987, 'auc': 0.94325, 'accuracy-SBM': 0.86842}
> Epoch 25: took 482.3s (avg 488.2s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 26, 'time_epoch': 422.72938, 'eta': 31192.80967, 'eta_hours': 8.66467, 'loss': 0.08895938, 'lr': 0.0004421, 'params': 384641, 'time_iter': 0.50687, 'accuracy': 0.8643, 'precision': 0.57677, 'recall': 0.86873, 'f1': 0.69326, 'auc': 0.94198, 'accuracy-SBM': 0.86604}
val: {'epoch': 26, 'time_epoch': 29.12856, 'loss': 0.09079404, 'lr': 0, 'params': 384641, 'time_iter': 0.17442, 'accuracy': 0.87972, 'precision': 0.61754, 'recall': 0.84195, 'f1': 0.71249, 'auc': 0.94241, 'accuracy-SBM': 0.86489}
test: {'epoch': 26, 'time_epoch': 29.50146, 'loss': 0.08977481, 'lr': 0, 'params': 384641, 'time_iter': 0.17666, 'accuracy': 0.88211, 'precision': 0.62203, 'recall': 0.84359, 'f1': 0.71606, 'auc': 0.94315, 'accuracy-SBM': 0.86697}
> Epoch 26: took 482.9s (avg 488.0s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 27, 'time_epoch': 422.56612, 'eta': 30753.34126, 'eta_hours': 8.54259, 'loss': 0.08890895, 'lr': 0.00043671, 'params': 384641, 'time_iter': 0.50667, 'accuracy': 0.86484, 'precision': 0.57794, 'recall': 0.86862, 'f1': 0.69408, 'auc': 0.94205, 'accuracy-SBM': 0.86632}
val: {'epoch': 27, 'time_epoch': 29.02312, 'loss': 0.09059799, 'lr': 0, 'params': 384641, 'time_iter': 0.17379, 'accuracy': 0.84674, 'precision': 0.54065, 'recall': 0.89254, 'f1': 0.6734, 'auc': 0.94223, 'accuracy-SBM': 0.86472}
test: {'epoch': 27, 'time_epoch': 29.35158, 'loss': 0.08941794, 'lr': 0, 'params': 384641, 'time_iter': 0.17576, 'accuracy': 0.85021, 'precision': 0.54582, 'recall': 0.89331, 'f1': 0.67761, 'auc': 0.94299, 'accuracy-SBM': 0.86715}
> Epoch 27: took 482.5s (avg 487.8s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 28, 'time_epoch': 422.72413, 'eta': 30315.42537, 'eta_hours': 8.42095, 'loss': 0.08890817, 'lr': 0.00043111, 'params': 384641, 'time_iter': 0.50686, 'accuracy': 0.86401, 'precision': 0.57612, 'recall': 0.86887, 'f1': 0.69284, 'auc': 0.94203, 'accuracy-SBM': 0.86592}
val: {'epoch': 28, 'time_epoch': 29.07269, 'loss': 0.09153671, 'lr': 0, 'params': 384641, 'time_iter': 0.17409, 'accuracy': 0.84825, 'precision': 0.54346, 'recall': 0.89281, 'f1': 0.67564, 'auc': 0.94225, 'accuracy-SBM': 0.86574}
test: {'epoch': 28, 'time_epoch': 29.5293, 'loss': 0.09025656, 'lr': 0, 'params': 384641, 'time_iter': 0.17682, 'accuracy': 0.85042, 'precision': 0.54634, 'recall': 0.89126, 'f1': 0.67742, 'auc': 0.94286, 'accuracy-SBM': 0.86647}
> Epoch 28: took 482.9s (avg 487.6s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 29, 'time_epoch': 423.63316, 'eta': 29880.64335, 'eta_hours': 8.30018, 'loss': 0.08886582, 'lr': 0.00042531, 'params': 384641, 'time_iter': 0.50795, 'accuracy': 0.8645, 'precision': 0.57722, 'recall': 0.86845, 'f1': 0.6935, 'auc': 0.94207, 'accuracy-SBM': 0.86605}
val: {'epoch': 29, 'time_epoch': 29.41172, 'loss': 0.09488668, 'lr': 0, 'params': 384641, 'time_iter': 0.17612, 'accuracy': 0.81493, 'precision': 0.48798, 'recall': 0.9233, 'f1': 0.6385, 'auc': 0.94183, 'accuracy-SBM': 0.85746}
test: {'epoch': 29, 'time_epoch': 29.34395, 'loss': 0.09355917, 'lr': 0, 'params': 384641, 'time_iter': 0.17571, 'accuracy': 0.81716, 'precision': 0.49002, 'recall': 0.9213, 'f1': 0.63976, 'auc': 0.94264, 'accuracy-SBM': 0.85809}
> Epoch 29: took 483.9s (avg 487.5s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 30, 'time_epoch': 422.64231, 'eta': 29444.37514, 'eta_hours': 8.17899, 'loss': 0.08877623, 'lr': 0.00041932, 'params': 384641, 'time_iter': 0.50677, 'accuracy': 0.86507, 'precision': 0.57851, 'recall': 0.86802, 'f1': 0.6943, 'auc': 0.94221, 'accuracy-SBM': 0.86623}
val: {'epoch': 30, 'time_epoch': 29.02274, 'loss': 0.09485597, 'lr': 0, 'params': 384641, 'time_iter': 0.17379, 'accuracy': 0.89234, 'precision': 0.66115, 'recall': 0.80372, 'f1': 0.7255, 'auc': 0.94119, 'accuracy-SBM': 0.85756}
test: {'epoch': 30, 'time_epoch': 29.35822, 'loss': 0.09391353, 'lr': 0, 'params': 384641, 'time_iter': 0.1758, 'accuracy': 0.89426, 'precision': 0.66557, 'recall': 0.80388, 'f1': 0.72822, 'auc': 0.94205, 'accuracy-SBM': 0.85874}
> Epoch 30: took 482.6s (avg 487.3s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 31, 'time_epoch': 422.76657, 'eta': 29009.22263, 'eta_hours': 8.05812, 'loss': 0.08879041, 'lr': 0.00041315, 'params': 384641, 'time_iter': 0.50691, 'accuracy': 0.86441, 'precision': 0.57696, 'recall': 0.86906, 'f1': 0.69351, 'auc': 0.94221, 'accuracy-SBM': 0.86623}
val: {'epoch': 31, 'time_epoch': 29.08232, 'loss': 0.0915266, 'lr': 0, 'params': 384641, 'time_iter': 0.17415, 'accuracy': 0.84698, 'precision': 0.54095, 'recall': 0.89538, 'f1': 0.67444, 'auc': 0.94274, 'accuracy-SBM': 0.86597}
test: {'epoch': 31, 'time_epoch': 29.39071, 'loss': 0.09029599, 'lr': 0, 'params': 384641, 'time_iter': 0.17599, 'accuracy': 0.8501, 'precision': 0.5456, 'recall': 0.89354, 'f1': 0.67751, 'auc': 0.94343, 'accuracy-SBM': 0.86718}
> Epoch 31: took 482.8s (avg 487.2s) | Best so far: epoch 16	train_loss: 0.0895 train_accuracy-SBM: 0.8652	val_loss: 0.0901 val_accuracy-SBM: 0.8663	test_loss: 0.0889 test_accuracy-SBM: 0.8678
-----------------------------------------------------------
train: {'epoch': 32, 'time_epoch': 422.39518, 'eta': 28574.06673, 'eta_hours': 7.93724, 'loss': 0.088667, 'lr': 0.00040679, 'params': 384641, 'time_iter': 0.50647, 'accuracy': 0.86453, 'precision': 0.57721, 'recall': 0.8692, 'f1': 0.69373, 'auc': 0.94239, 'accuracy-SBM': 0.86637}
val: {'epoch': 32, 'time_epoch': 29.11565, 'loss': 0.09056331, 'lr': 0, 'params': 384641, 'time_iter': 0.17435, 'accuracy': 0.86437, 'precision': 0.57748, 'recall': 0.87134, 'f1': 0.69461, 'auc': 0.94276, 'accuracy-SBM': 0.8671}
test: {'epoch': 32, 'time_epoch': 29.43589, 'loss': 0.08937281, 'lr': 0, 'params': 384641, 'time_iter': 0.17626, 'accuracy': 0.86733, 'precision': 0.58265, 'recall': 0.87108, 'f1': 0.69826, 'auc': 0.94353, 'accuracy-SBM': 0.86881}
> Epoch 32: took 482.5s (avg 487.0s) | Best so far: epoch 32	train_loss: 0.0887 train_accuracy-SBM: 0.8664	val_loss: 0.0906 val_accuracy-SBM: 0.8671	test_loss: 0.0894 test_accuracy-SBM: 0.8688
-----------------------------------------------------------
train: {'epoch': 33, 'time_epoch': 422.75374, 'eta': 28140.35749, 'eta_hours': 7.81677, 'loss': 0.08865592, 'lr': 0.00040027, 'params': 384641, 'time_iter': 0.5069, 'accuracy': 0.86501, 'precision': 0.57825, 'recall': 0.8693, 'f1': 0.69451, 'auc': 0.9424, 'accuracy-SBM': 0.8667}
val: {'epoch': 33, 'time_epoch': 29.0537, 'loss': 0.09101406, 'lr': 0, 'params': 384641, 'time_iter': 0.17397, 'accuracy': 0.84582, 'precision': 0.53882, 'recall': 0.89526, 'f1': 0.67275, 'auc': 0.94262, 'accuracy-SBM': 0.86522}
test: {'epoch': 33, 'time_epoch': 29.34328, 'loss': 0.08986846, 'lr': 0, 'params': 384641, 'time_iter': 0.17571, 'accuracy': 0.84914, 'precision': 0.54374, 'recall': 0.89452, 'f1': 0.67636, 'auc': 0.94332, 'accuracy-SBM': 0.86698}
> Epoch 33: took 482.7s (avg 486.9s) | Best so far: epoch 32	train_loss: 0.0887 train_accuracy-SBM: 0.8664	val_loss: 0.0906 val_accuracy-SBM: 0.8671	test_loss: 0.0894 test_accuracy-SBM: 0.8688
-----------------------------------------------------------
train: {'epoch': 34, 'time_epoch': 422.54499, 'eta': 27706.88661, 'eta_hours': 7.69636, 'loss': 0.08856529, 'lr': 0.00039358, 'params': 384641, 'time_iter': 0.50665, 'accuracy': 0.86369, 'precision': 0.5752, 'recall': 0.87106, 'f1': 0.69287, 'auc': 0.94251, 'accuracy-SBM': 0.86658}
val: {'epoch': 34, 'time_epoch': 29.14451, 'loss': 0.09270104, 'lr': 0, 'params': 384641, 'time_iter': 0.17452, 'accuracy': 0.84223, 'precision': 0.53215, 'recall': 0.90002, 'f1': 0.66884, 'auc': 0.94283, 'accuracy-SBM': 0.86491}
test: {'epoch': 34, 'time_epoch': 29.33126, 'loss': 0.09142521, 'lr': 0, 'params': 384641, 'time_iter': 0.17564, 'accuracy': 0.84546, 'precision': 0.53672, 'recall': 0.89907, 'f1': 0.67218, 'auc': 0.9436, 'accuracy-SBM': 0.86653}
> Epoch 34: took 482.6s (avg 486.8s) | Best so far: epoch 32	train_loss: 0.0887 train_accuracy-SBM: 0.8664	val_loss: 0.0906 val_accuracy-SBM: 0.8671	test_loss: 0.0894 test_accuracy-SBM: 0.8688
-----------------------------------------------------------
train: {'epoch': 35, 'time_epoch': 422.88918, 'eta': 27274.63461, 'eta_hours': 7.57629, 'loss': 0.08845644, 'lr': 0.00038674, 'params': 384641, 'time_iter': 0.50706, 'accuracy': 0.86513, 'precision': 0.57851, 'recall': 0.86926, 'f1': 0.69469, 'auc': 0.94269, 'accuracy-SBM': 0.86675}
val: {'epoch': 35, 'time_epoch': 29.27235, 'loss': 0.09058721, 'lr': 0, 'params': 384641, 'time_iter': 0.17528, 'accuracy': 0.87623, 'precision': 0.60735, 'recall': 0.85102, 'f1': 0.70883, 'auc': 0.94263, 'accuracy-SBM': 0.86634}
test: {'epoch': 35, 'time_epoch': 29.44484, 'loss': 0.08946562, 'lr': 0, 'params': 384641, 'time_iter': 0.17632, 'accuracy': 0.87924, 'precision': 0.61332, 'recall': 0.85172, 'f1': 0.71312, 'auc': 0.94348, 'accuracy-SBM': 0.86842}
> Epoch 35: took 483.2s (avg 486.7s) | Best so far: epoch 32	train_loss: 0.0887 train_accuracy-SBM: 0.8664	val_loss: 0.0906 val_accuracy-SBM: 0.8671	test_loss: 0.0894 test_accuracy-SBM: 0.8688
-----------------------------------------------------------
train: {'epoch': 36, 'time_epoch': 422.78137, 'eta': 26842.70514, 'eta_hours': 7.45631, 'loss': 0.08844632, 'lr': 0.00037974, 'params': 384641, 'time_iter': 0.50693, 'accuracy': 0.86503, 'precision': 0.57818, 'recall': 0.87031, 'f1': 0.69479, 'auc': 0.9427, 'accuracy-SBM': 0.8671}
val: {'epoch': 36, 'time_epoch': 29.06865, 'loss': 0.09184014, 'lr': 0, 'params': 384641, 'time_iter': 0.17406, 'accuracy': 0.88475, 'precision': 0.63276, 'recall': 0.83161, 'f1': 0.71868, 'auc': 0.94251, 'accuracy-SBM': 0.8639}
test: {'epoch': 36, 'time_epoch': 29.39933, 'loss': 0.09082569, 'lr': 0, 'params': 384641, 'time_iter': 0.17604, 'accuracy': 0.88715, 'precision': 0.63784, 'recall': 0.83202, 'f1': 0.7221, 'auc': 0.94323, 'accuracy-SBM': 0.86548}
> Epoch 36: took 482.7s (avg 486.6s) | Best so far: epoch 32	train_loss: 0.0887 train_accuracy-SBM: 0.8664	val_loss: 0.0906 val_accuracy-SBM: 0.8671	test_loss: 0.0894 test_accuracy-SBM: 0.8688
-----------------------------------------------------------
train: {'epoch': 37, 'time_epoch': 423.28669, 'eta': 26412.08163, 'eta_hours': 7.33669, 'loss': 0.08833761, 'lr': 0.00037261, 'params': 384641, 'time_iter': 0.50754, 'accuracy': 0.86545, 'precision': 0.57912, 'recall': 0.87009, 'f1': 0.6954, 'auc': 0.94279, 'accuracy-SBM': 0.86727}
val: {'epoch': 37, 'time_epoch': 29.03265, 'loss': 0.09121105, 'lr': 0, 'params': 384641, 'time_iter': 0.17385, 'accuracy': 0.85114, 'precision': 0.54912, 'recall': 0.88909, 'f1': 0.67893, 'auc': 0.9426, 'accuracy-SBM': 0.86603}
test: {'epoch': 37, 'time_epoch': 29.31179, 'loss': 0.08989807, 'lr': 0, 'params': 384641, 'time_iter': 0.17552, 'accuracy': 0.85469, 'precision': 0.55477, 'recall': 0.88842, 'f1': 0.68303, 'auc': 0.94347, 'accuracy-SBM': 0.86795}
> Epoch 37: took 483.2s (avg 486.5s) | Best so far: epoch 32	train_loss: 0.0887 train_accuracy-SBM: 0.8664	val_loss: 0.0906 val_accuracy-SBM: 0.8671	test_loss: 0.0894 test_accuracy-SBM: 0.8688
-----------------------------------------------------------
train: {'epoch': 38, 'time_epoch': 422.47993, 'eta': 25980.57251, 'eta_hours': 7.21683, 'loss': 0.08836114, 'lr': 0.00036534, 'params': 384641, 'time_iter': 0.50657, 'accuracy': 0.86492, 'precision': 0.57794, 'recall': 0.87031, 'f1': 0.69461, 'auc': 0.94279, 'accuracy-SBM': 0.86703}
val: {'epoch': 38, 'time_epoch': 29.19716, 'loss': 0.08968334, 'lr': 0, 'params': 384641, 'time_iter': 0.17483, 'accuracy': 0.87223, 'precision': 0.59655, 'recall': 0.85962, 'f1': 0.70432, 'auc': 0.94303, 'accuracy-SBM': 0.86729}
test: {'epoch': 38, 'time_epoch': 29.29884, 'loss': 0.08867809, 'lr': 0, 'params': 384641, 'time_iter': 0.17544, 'accuracy': 0.875, 'precision': 0.60173, 'recall': 0.8597, 'f1': 0.70795, 'auc': 0.94366, 'accuracy-SBM': 0.86899}
> Epoch 38: took 482.5s (avg 486.4s) | Best so far: epoch 38	train_loss: 0.0884 train_accuracy-SBM: 0.8670	val_loss: 0.0897 val_accuracy-SBM: 0.8673	test_loss: 0.0887 test_accuracy-SBM: 0.8690
-----------------------------------------------------------
train: {'epoch': 39, 'time_epoch': 422.05445, 'eta': 25548.87662, 'eta_hours': 7.09691, 'loss': 0.08820847, 'lr': 0.00035794, 'params': 384641, 'time_iter': 0.50606, 'accuracy': 0.86593, 'precision': 0.58019, 'recall': 0.86985, 'f1': 0.69609, 'auc': 0.94301, 'accuracy-SBM': 0.86747}
val: {'epoch': 39, 'time_epoch': 29.08603, 'loss': 0.09009166, 'lr': 0, 'params': 384641, 'time_iter': 0.17417, 'accuracy': 0.8631, 'precision': 0.57438, 'recall': 0.87511, 'f1': 0.69355, 'auc': 0.94307, 'accuracy-SBM': 0.86781}
test: {'epoch': 39, 'time_epoch': 29.37511, 'loss': 0.08892304, 'lr': 0, 'params': 384641, 'time_iter': 0.1759, 'accuracy': 0.8661, 'precision': 0.57961, 'recall': 0.87415, 'f1': 0.69705, 'auc': 0.94383, 'accuracy-SBM': 0.86926}
> Epoch 39: took 482.1s (avg 486.3s) | Best so far: epoch 39	train_loss: 0.0882 train_accuracy-SBM: 0.8675	val_loss: 0.0901 val_accuracy-SBM: 0.8678	test_loss: 0.0889 test_accuracy-SBM: 0.8693
-----------------------------------------------------------
train: {'epoch': 40, 'time_epoch': 422.57043, 'eta': 25118.39355, 'eta_hours': 6.97733, 'loss': 0.08814853, 'lr': 0.00035042, 'params': 384641, 'time_iter': 0.50668, 'accuracy': 0.86552, 'precision': 0.57913, 'recall': 0.87143, 'f1': 0.69583, 'auc': 0.94308, 'accuracy-SBM': 0.86784}
val: {'epoch': 40, 'time_epoch': 29.09863, 'loss': 0.08981769, 'lr': 0, 'params': 384641, 'time_iter': 0.17424, 'accuracy': 0.8694, 'precision': 0.58932, 'recall': 0.86513, 'f1': 0.70107, 'auc': 0.94311, 'accuracy-SBM': 0.86772}
test: {'epoch': 40, 'time_epoch': 29.40078, 'loss': 0.08883497, 'lr': 0, 'params': 384641, 'time_iter': 0.17605, 'accuracy': 0.8722, 'precision': 0.59435, 'recall': 0.86544, 'f1': 0.70472, 'auc': 0.94378, 'accuracy-SBM': 0.86954}
> Epoch 40: took 482.6s (avg 486.2s) | Best so far: epoch 39	train_loss: 0.0882 train_accuracy-SBM: 0.8675	val_loss: 0.0901 val_accuracy-SBM: 0.8678	test_loss: 0.0889 test_accuracy-SBM: 0.8693
-----------------------------------------------------------
train: {'epoch': 41, 'time_epoch': 422.4678, 'eta': 24688.14556, 'eta_hours': 6.85782, 'loss': 0.08807103, 'lr': 0.0003428, 'params': 384641, 'time_iter': 0.50656, 'accuracy': 0.86497, 'precision': 0.5779, 'recall': 0.87182, 'f1': 0.69506, 'auc': 0.94319, 'accuracy-SBM': 0.86766}
val: {'epoch': 41, 'time_epoch': 29.08939, 'loss': 0.09043958, 'lr': 0, 'params': 384641, 'time_iter': 0.17419, 'accuracy': 0.87525, 'precision': 0.60434, 'recall': 0.85505, 'f1': 0.70816, 'auc': 0.94336, 'accuracy-SBM': 0.86732}
test: {'epoch': 41, 'time_epoch': 29.55989, 'loss': 0.08952593, 'lr': 0, 'params': 384641, 'time_iter': 0.17701, 'accuracy': 0.87799, 'precision': 0.6096, 'recall': 0.8556, 'f1': 0.71195, 'auc': 0.94393, 'accuracy-SBM': 0.86919}
> Epoch 41: took 482.7s (avg 486.1s) | Best so far: epoch 39	train_loss: 0.0882 train_accuracy-SBM: 0.8675	val_loss: 0.0901 val_accuracy-SBM: 0.8678	test_loss: 0.0889 test_accuracy-SBM: 0.8693
-----------------------------------------------------------
train: {'epoch': 42, 'time_epoch': 422.49081, 'eta': 24258.28993, 'eta_hours': 6.73841, 'loss': 0.08795783, 'lr': 0.00033507, 'params': 384641, 'time_iter': 0.50658, 'accuracy': 0.86521, 'precision': 0.57842, 'recall': 0.87175, 'f1': 0.69542, 'auc': 0.94329, 'accuracy-SBM': 0.86778}
val: {'epoch': 42, 'time_epoch': 29.04758, 'loss': 0.08989712, 'lr': 0, 'params': 384641, 'time_iter': 0.17394, 'accuracy': 0.86308, 'precision': 0.57428, 'recall': 0.87566, 'f1': 0.69364, 'auc': 0.94319, 'accuracy-SBM': 0.86801}
test: {'epoch': 42, 'time_epoch': 29.50792, 'loss': 0.08877879, 'lr': 0, 'params': 384641, 'time_iter': 0.17669, 'accuracy': 0.86582, 'precision': 0.57881, 'recall': 0.87608, 'f1': 0.69707, 'auc': 0.94396, 'accuracy-SBM': 0.86985}
> Epoch 42: took 482.6s (avg 486.0s) | Best so far: epoch 42	train_loss: 0.0880 train_accuracy-SBM: 0.8678	val_loss: 0.0899 val_accuracy-SBM: 0.8680	test_loss: 0.0888 test_accuracy-SBM: 0.8699
-----------------------------------------------------------
train: {'epoch': 43, 'time_epoch': 422.53644, 'eta': 23828.82714, 'eta_hours': 6.61912, 'loss': 0.0878369, 'lr': 0.00032725, 'params': 384641, 'time_iter': 0.50664, 'accuracy': 0.86588, 'precision': 0.57994, 'recall': 0.8712, 'f1': 0.69634, 'auc': 0.94351, 'accuracy-SBM': 0.86797}
val: {'epoch': 43, 'time_epoch': 29.1394, 'loss': 0.08950768, 'lr': 0, 'params': 384641, 'time_iter': 0.17449, 'accuracy': 0.87293, 'precision': 0.59818, 'recall': 0.8597, 'f1': 0.70548, 'auc': 0.94354, 'accuracy-SBM': 0.86774}
test: {'epoch': 43, 'time_epoch': 29.25823, 'loss': 0.08846976, 'lr': 0, 'params': 384641, 'time_iter': 0.1752, 'accuracy': 0.8756, 'precision': 0.60291, 'recall': 0.86139, 'f1': 0.70934, 'auc': 0.94428, 'accuracy-SBM': 0.87001}
> Epoch 43: took 482.5s (avg 485.9s) | Best so far: epoch 42	train_loss: 0.0880 train_accuracy-SBM: 0.8678	val_loss: 0.0899 val_accuracy-SBM: 0.8680	test_loss: 0.0888 test_accuracy-SBM: 0.8699
-----------------------------------------------------------
train: {'epoch': 44, 'time_epoch': 422.66539, 'eta': 23399.8298, 'eta_hours': 6.49995, 'loss': 0.08775583, 'lr': 0.00031935, 'params': 384641, 'time_iter': 0.50679, 'accuracy': 0.86522, 'precision': 0.57837, 'recall': 0.87244, 'f1': 0.6956, 'auc': 0.94362, 'accuracy-SBM': 0.86805}
val: {'epoch': 44, 'time_epoch': 29.08398, 'loss': 0.09028769, 'lr': 0, 'params': 384641, 'time_iter': 0.17416, 'accuracy': 0.84853, 'precision': 0.54388, 'recall': 0.89438, 'f1': 0.67643, 'auc': 0.94328, 'accuracy-SBM': 0.86652}
test: {'epoch': 44, 'time_epoch': 29.46043, 'loss': 0.08907973, 'lr': 0, 'params': 384641, 'time_iter': 0.17641, 'accuracy': 0.85169, 'precision': 0.54859, 'recall': 0.8939, 'f1': 0.67992, 'auc': 0.94398, 'accuracy-SBM': 0.86828}
> Epoch 44: took 482.7s (avg 485.9s) | Best so far: epoch 42	train_loss: 0.0880 train_accuracy-SBM: 0.8678	val_loss: 0.0899 val_accuracy-SBM: 0.8680	test_loss: 0.0888 test_accuracy-SBM: 0.8699
-----------------------------------------------------------
train: {'epoch': 45, 'time_epoch': 422.36496, 'eta': 22970.75507, 'eta_hours': 6.38077, 'loss': 0.08758515, 'lr': 0.00031137, 'params': 384641, 'time_iter': 0.50643, 'accuracy': 0.86567, 'precision': 0.57937, 'recall': 0.87221, 'f1': 0.69625, 'auc': 0.94386, 'accuracy-SBM': 0.86824}
val: {'epoch': 45, 'time_epoch': 28.98547, 'loss': 0.09158042, 'lr': 0, 'params': 384641, 'time_iter': 0.17357, 'accuracy': 0.88216, 'precision': 0.62517, 'recall': 0.83485, 'f1': 0.71495, 'auc': 0.94237, 'accuracy-SBM': 0.86359}
test: {'epoch': 45, 'time_epoch': 29.6325, 'loss': 0.09055417, 'lr': 0, 'params': 384641, 'time_iter': 0.17744, 'accuracy': 0.88509, 'precision': 0.63137, 'recall': 0.83602, 'f1': 0.71942, 'auc': 0.9432, 'accuracy-SBM': 0.8658}
> Epoch 45: took 482.5s (avg 485.8s) | Best so far: epoch 42	train_loss: 0.0880 train_accuracy-SBM: 0.8678	val_loss: 0.0899 val_accuracy-SBM: 0.8680	test_loss: 0.0888 test_accuracy-SBM: 0.8699
-----------------------------------------------------------
train: {'epoch': 46, 'time_epoch': 422.08849, 'eta': 22541.65411, 'eta_hours': 6.26157, 'loss': 0.08756308, 'lr': 0.00030332, 'params': 384641, 'time_iter': 0.5061, 'accuracy': 0.86608, 'precision': 0.5803, 'recall': 0.87192, 'f1': 0.69683, 'auc': 0.94385, 'accuracy-SBM': 0.86838}
val: {'epoch': 46, 'time_epoch': 29.12458, 'loss': 0.08975689, 'lr': 0, 'params': 384641, 'time_iter': 0.1744, 'accuracy': 0.86169, 'precision': 0.57104, 'recall': 0.87904, 'f1': 0.69233, 'auc': 0.94361, 'accuracy-SBM': 0.8685}
test: {'epoch': 46, 'time_epoch': 29.38424, 'loss': 0.08869936, 'lr': 0, 'params': 384641, 'time_iter': 0.17595, 'accuracy': 0.86433, 'precision': 0.57533, 'recall': 0.8787, 'f1': 0.69537, 'auc': 0.9442, 'accuracy-SBM': 0.86998}
> Epoch 46: took 482.1s (avg 485.7s) | Best so far: epoch 46	train_loss: 0.0876 train_accuracy-SBM: 0.8684	val_loss: 0.0898 val_accuracy-SBM: 0.8685	test_loss: 0.0887 test_accuracy-SBM: 0.8700
-----------------------------------------------------------
train: {'epoch': 47, 'time_epoch': 422.64266, 'eta': 22113.44568, 'eta_hours': 6.14262, 'loss': 0.08749434, 'lr': 0.00029522, 'params': 384641, 'time_iter': 0.50677, 'accuracy': 0.86643, 'precision': 0.58113, 'recall': 0.87145, 'f1': 0.69727, 'auc': 0.94396, 'accuracy-SBM': 0.8684}
val: {'epoch': 47, 'time_epoch': 29.17328, 'loss': 0.09148789, 'lr': 0, 'params': 384641, 'time_iter': 0.17469, 'accuracy': 0.83497, 'precision': 0.51942, 'recall': 0.906, 'f1': 0.66029, 'auc': 0.94254, 'accuracy-SBM': 0.86285}
test: {'epoch': 47, 'time_epoch': 29.53991, 'loss': 0.09037067, 'lr': 0, 'params': 384641, 'time_iter': 0.17689, 'accuracy': 0.83873, 'precision': 0.52458, 'recall': 0.90553, 'f1': 0.66431, 'auc': 0.94306, 'accuracy-SBM': 0.86499}
> Epoch 47: took 482.9s (avg 485.7s) | Best so far: epoch 46	train_loss: 0.0876 train_accuracy-SBM: 0.8684	val_loss: 0.0898 val_accuracy-SBM: 0.8685	test_loss: 0.0887 test_accuracy-SBM: 0.8700
-----------------------------------------------------------
train: {'epoch': 48, 'time_epoch': 422.57708, 'eta': 21685.39617, 'eta_hours': 6.02372, 'loss': 0.08734988, 'lr': 0.00028707, 'params': 384641, 'time_iter': 0.50669, 'accuracy': 0.86638, 'precision': 0.5809, 'recall': 0.87252, 'f1': 0.69745, 'auc': 0.94416, 'accuracy-SBM': 0.86879}
val: {'epoch': 48, 'time_epoch': 29.1972, 'loss': 0.09045871, 'lr': 0, 'params': 384641, 'time_iter': 0.17483, 'accuracy': 0.88237, 'precision': 0.62443, 'recall': 0.84185, 'f1': 0.71702, 'auc': 0.94353, 'accuracy-SBM': 0.86647}
test: {'epoch': 48, 'time_epoch': 29.36436, 'loss': 0.0895569, 'lr': 0, 'params': 384641, 'time_iter': 0.17583, 'accuracy': 0.88497, 'precision': 0.62979, 'recall': 0.8424, 'f1': 0.72074, 'auc': 0.9442, 'accuracy-SBM': 0.86824}
> Epoch 48: took 482.7s (avg 485.6s) | Best so far: epoch 46	train_loss: 0.0876 train_accuracy-SBM: 0.8684	val_loss: 0.0898 val_accuracy-SBM: 0.8685	test_loss: 0.0887 test_accuracy-SBM: 0.8700
-----------------------------------------------------------
train: {'epoch': 49, 'time_epoch': 422.22006, 'eta': 21257.20854, 'eta_hours': 5.90478, 'loss': 0.08722168, 'lr': 0.00027887, 'params': 384641, 'time_iter': 0.50626, 'accuracy': 0.8661, 'precision': 0.5802, 'recall': 0.87319, 'f1': 0.69717, 'auc': 0.94434, 'accuracy-SBM': 0.86888}
val: {'epoch': 49, 'time_epoch': 29.14123, 'loss': 0.0907483, 'lr': 0, 'params': 384641, 'time_iter': 0.1745, 'accuracy': 0.87864, 'precision': 0.61394, 'recall': 0.84721, 'f1': 0.71195, 'auc': 0.94324, 'accuracy-SBM': 0.86631}
test: {'epoch': 49, 'time_epoch': 29.52929, 'loss': 0.08973606, 'lr': 0, 'params': 384641, 'time_iter': 0.17682, 'accuracy': 0.88156, 'precision': 0.6198, 'recall': 0.84814, 'f1': 0.71621, 'auc': 0.944, 'accuracy-SBM': 0.86842}
> Epoch 49: took 482.4s (avg 485.5s) | Best so far: epoch 46	train_loss: 0.0876 train_accuracy-SBM: 0.8684	val_loss: 0.0898 val_accuracy-SBM: 0.8685	test_loss: 0.0887 test_accuracy-SBM: 0.8700
-----------------------------------------------------------
train: {'epoch': 50, 'time_epoch': 423.00125, 'eta': 20830.00548, 'eta_hours': 5.78611, 'loss': 0.08703955, 'lr': 0.00027064, 'params': 384641, 'time_iter': 0.5072, 'accuracy': 0.86658, 'precision': 0.58118, 'recall': 0.87391, 'f1': 0.6981, 'auc': 0.9446, 'accuracy-SBM': 0.86946}
val: {'epoch': 50, 'time_epoch': 29.05604, 'loss': 0.088867, 'lr': 0, 'params': 384641, 'time_iter': 0.17399, 'accuracy': 0.86666, 'precision': 0.5824, 'recall': 0.87206, 'f1': 0.69839, 'auc': 0.94372, 'accuracy-SBM': 0.86878}
test: {'epoch': 50, 'time_epoch': 29.39441, 'loss': 0.08791234, 'lr': 0, 'params': 384641, 'time_iter': 0.17601, 'accuracy': 0.86963, 'precision': 0.58776, 'recall': 0.8713, 'f1': 0.70198, 'auc': 0.94428, 'accuracy-SBM': 0.87029}
> Epoch 50: took 483.0s (avg 485.5s) | Best so far: epoch 50	train_loss: 0.0870 train_accuracy-SBM: 0.8695	val_loss: 0.0889 val_accuracy-SBM: 0.8688	test_loss: 0.0879 test_accuracy-SBM: 0.8703
-----------------------------------------------------------
train: {'epoch': 51, 'time_epoch': 422.39837, 'eta': 20402.40753, 'eta_hours': 5.66734, 'loss': 0.08690256, 'lr': 0.0002624, 'params': 384641, 'time_iter': 0.50647, 'accuracy': 0.86739, 'precision': 0.58306, 'recall': 0.87304, 'f1': 0.69917, 'auc': 0.94479, 'accuracy-SBM': 0.86961}
val: {'epoch': 51, 'time_epoch': 29.11822, 'loss': 0.08918103, 'lr': 0, 'params': 384641, 'time_iter': 0.17436, 'accuracy': 0.86509, 'precision': 0.57855, 'recall': 0.87606, 'f1': 0.69688, 'auc': 0.9439, 'accuracy-SBM': 0.86939}
test: {'epoch': 51, 'time_epoch': 29.44791, 'loss': 0.08798062, 'lr': 0, 'params': 384641, 'time_iter': 0.17633, 'accuracy': 0.8682, 'precision': 0.58413, 'recall': 0.87499, 'f1': 0.70057, 'auc': 0.94471, 'accuracy-SBM': 0.87087}
> Epoch 51: took 482.5s (avg 485.4s) | Best so far: epoch 51	train_loss: 0.0869 train_accuracy-SBM: 0.8696	val_loss: 0.0892 val_accuracy-SBM: 0.8694	test_loss: 0.0880 test_accuracy-SBM: 0.8709
-----------------------------------------------------------
train: {'epoch': 52, 'time_epoch': 423.05266, 'eta': 19975.58601, 'eta_hours': 5.54877, 'loss': 0.086758, 'lr': 0.00025413, 'params': 384641, 'time_iter': 0.50726, 'accuracy': 0.86754, 'precision': 0.58326, 'recall': 0.87412, 'f1': 0.69967, 'auc': 0.94497, 'accuracy-SBM': 0.87012}
val: {'epoch': 52, 'time_epoch': 28.99199, 'loss': 0.08942691, 'lr': 0, 'params': 384641, 'time_iter': 0.1736, 'accuracy': 0.86732, 'precision': 0.58376, 'recall': 0.87287, 'f1': 0.69962, 'auc': 0.94415, 'accuracy-SBM': 0.8695}
test: {'epoch': 52, 'time_epoch': 29.52476, 'loss': 0.08839938, 'lr': 0, 'params': 384641, 'time_iter': 0.17679, 'accuracy': 0.87035, 'precision': 0.58928, 'recall': 0.87211, 'f1': 0.70333, 'auc': 0.94479, 'accuracy-SBM': 0.87104}
> Epoch 52: took 483.1s (avg 485.4s) | Best so far: epoch 52	train_loss: 0.0868 train_accuracy-SBM: 0.8701	val_loss: 0.0894 val_accuracy-SBM: 0.8695	test_loss: 0.0884 test_accuracy-SBM: 0.8710
-----------------------------------------------------------
train: {'epoch': 53, 'time_epoch': 422.55433, 'eta': 19548.47957, 'eta_hours': 5.43013, 'loss': 0.08669613, 'lr': 0.00024587, 'params': 384641, 'time_iter': 0.50666, 'accuracy': 0.86662, 'precision': 0.58117, 'recall': 0.87483, 'f1': 0.69838, 'auc': 0.945, 'accuracy-SBM': 0.86984}
val: {'epoch': 53, 'time_epoch': 29.16352, 'loss': 0.0889156, 'lr': 0, 'params': 384641, 'time_iter': 0.17463, 'accuracy': 0.86807, 'precision': 0.58547, 'recall': 0.87251, 'f1': 0.70073, 'auc': 0.94413, 'accuracy-SBM': 0.86981}
test: {'epoch': 53, 'time_epoch': 29.53374, 'loss': 0.08788507, 'lr': 0, 'params': 384641, 'time_iter': 0.17685, 'accuracy': 0.87082, 'precision': 0.59052, 'recall': 0.8707, 'f1': 0.70375, 'auc': 0.94481, 'accuracy-SBM': 0.87077}
> Epoch 53: took 482.8s (avg 485.3s) | Best so far: epoch 53	train_loss: 0.0867 train_accuracy-SBM: 0.8698	val_loss: 0.0889 val_accuracy-SBM: 0.8698	test_loss: 0.0879 test_accuracy-SBM: 0.8708
-----------------------------------------------------------
train: {'epoch': 54, 'time_epoch': 422.52572, 'eta': 19121.51525, 'eta_hours': 5.31153, 'loss': 0.08660811, 'lr': 0.0002376, 'params': 384641, 'time_iter': 0.50663, 'accuracy': 0.86719, 'precision': 0.58246, 'recall': 0.87437, 'f1': 0.69917, 'auc': 0.94513, 'accuracy-SBM': 0.87001}
val: {'epoch': 54, 'time_epoch': 29.0106, 'loss': 0.08965904, 'lr': 0, 'params': 384641, 'time_iter': 0.17372, 'accuracy': 0.85796, 'precision': 0.56266, 'recall': 0.88721, 'f1': 0.68861, 'auc': 0.94426, 'accuracy-SBM': 0.86944}
test: {'epoch': 54, 'time_epoch': 29.51521, 'loss': 0.0886706, 'lr': 0, 'params': 384641, 'time_iter': 0.17674, 'accuracy': 0.86033, 'precision': 0.56641, 'recall': 0.88459, 'f1': 0.69061, 'auc': 0.94478, 'accuracy-SBM': 0.86987}
> Epoch 54: took 482.6s (avg 485.3s) | Best so far: epoch 53	train_loss: 0.0867 train_accuracy-SBM: 0.8698	val_loss: 0.0889 val_accuracy-SBM: 0.8698	test_loss: 0.0879 test_accuracy-SBM: 0.8708
-----------------------------------------------------------
train: {'epoch': 55, 'time_epoch': 423.24051, 'eta': 18695.27108, 'eta_hours': 5.19313, 'loss': 0.08636245, 'lr': 0.00022936, 'params': 384641, 'time_iter': 0.50748, 'accuracy': 0.86759, 'precision': 0.58344, 'recall': 0.87371, 'f1': 0.69966, 'auc': 0.94546, 'accuracy-SBM': 0.87}
val: {'epoch': 55, 'time_epoch': 29.23218, 'loss': 0.08919687, 'lr': 0, 'params': 384641, 'time_iter': 0.17504, 'accuracy': 0.86663, 'precision': 0.58205, 'recall': 0.87461, 'f1': 0.69895, 'auc': 0.94431, 'accuracy-SBM': 0.86976}
test: {'epoch': 55, 'time_epoch': 29.35981, 'loss': 0.08817234, 'lr': 0, 'params': 384641, 'time_iter': 0.17581, 'accuracy': 0.86956, 'precision': 0.58742, 'recall': 0.87287, 'f1': 0.70224, 'auc': 0.94499, 'accuracy-SBM': 0.87086}
> Epoch 55: took 483.4s (avg 485.3s) | Best so far: epoch 53	train_loss: 0.0867 train_accuracy-SBM: 0.8698	val_loss: 0.0889 val_accuracy-SBM: 0.8698	test_loss: 0.0879 test_accuracy-SBM: 0.8708
-----------------------------------------------------------
train: {'epoch': 56, 'time_epoch': 422.27982, 'eta': 18268.40756, 'eta_hours': 5.07456, 'loss': 0.08628845, 'lr': 0.00022113, 'params': 384641, 'time_iter': 0.50633, 'accuracy': 0.8678, 'precision': 0.58377, 'recall': 0.87476, 'f1': 0.70024, 'auc': 0.94551, 'accuracy-SBM': 0.87053}
val: {'epoch': 56, 'time_epoch': 29.33912, 'loss': 0.08959291, 'lr': 0, 'params': 384641, 'time_iter': 0.17568, 'accuracy': 0.85751, 'precision': 0.56171, 'recall': 0.88785, 'f1': 0.68809, 'auc': 0.94412, 'accuracy-SBM': 0.86942}
test: {'epoch': 56, 'time_epoch': 29.48034, 'loss': 0.08839486, 'lr': 0, 'params': 384641, 'time_iter': 0.17653, 'accuracy': 0.86005, 'precision': 0.56571, 'recall': 0.88597, 'f1': 0.69051, 'auc': 0.94489, 'accuracy-SBM': 0.87024}
> Epoch 56: took 482.7s (avg 485.2s) | Best so far: epoch 53	train_loss: 0.0867 train_accuracy-SBM: 0.8698	val_loss: 0.0889 val_accuracy-SBM: 0.8698	test_loss: 0.0879 test_accuracy-SBM: 0.8708
-----------------------------------------------------------
train: {'epoch': 57, 'time_epoch': 422.40816, 'eta': 17841.79504, 'eta_hours': 4.95605, 'loss': 0.08600273, 'lr': 0.00021293, 'params': 384641, 'time_iter': 0.50648, 'accuracy': 0.86815, 'precision': 0.58448, 'recall': 0.87545, 'f1': 0.70097, 'auc': 0.94594, 'accuracy-SBM': 0.87102}
val: {'epoch': 57, 'time_epoch': 29.12995, 'loss': 0.08886092, 'lr': 0, 'params': 384641, 'time_iter': 0.17443, 'accuracy': 0.86935, 'precision': 0.58852, 'recall': 0.87087, 'f1': 0.70238, 'auc': 0.94432, 'accuracy-SBM': 0.86995}
test: {'epoch': 57, 'time_epoch': 29.53195, 'loss': 0.08787439, 'lr': 0, 'params': 384641, 'time_iter': 0.17684, 'accuracy': 0.87199, 'precision': 0.59337, 'recall': 0.86922, 'f1': 0.70528, 'auc': 0.94498, 'accuracy-SBM': 0.8709}
> Epoch 57: took 482.6s (avg 485.2s) | Best so far: epoch 57	train_loss: 0.0860 train_accuracy-SBM: 0.8710	val_loss: 0.0889 val_accuracy-SBM: 0.8700	test_loss: 0.0879 test_accuracy-SBM: 0.8709
-----------------------------------------------------------
train: {'epoch': 58, 'time_epoch': 421.96459, 'eta': 17415.0168, 'eta_hours': 4.8375, 'loss': 0.08596735, 'lr': 0.00020478, 'params': 384641, 'time_iter': 0.50595, 'accuracy': 0.86719, 'precision': 0.58219, 'recall': 0.87689, 'f1': 0.69978, 'auc': 0.94591, 'accuracy-SBM': 0.871}
val: {'epoch': 58, 'time_epoch': 29.08775, 'loss': 0.08899735, 'lr': 0, 'params': 384641, 'time_iter': 0.17418, 'accuracy': 0.86268, 'precision': 0.57298, 'recall': 0.88051, 'f1': 0.69421, 'auc': 0.94447, 'accuracy-SBM': 0.86968}
test: {'epoch': 58, 'time_epoch': 29.41673, 'loss': 0.08789937, 'lr': 0, 'params': 384641, 'time_iter': 0.17615, 'accuracy': 0.86575, 'precision': 0.57824, 'recall': 0.8802, 'f1': 0.69796, 'auc': 0.94521, 'accuracy-SBM': 0.87143}
> Epoch 58: took 482.0s (avg 485.1s) | Best so far: epoch 57	train_loss: 0.0860 train_accuracy-SBM: 0.8710	val_loss: 0.0889 val_accuracy-SBM: 0.8700	test_loss: 0.0879 test_accuracy-SBM: 0.8709
-----------------------------------------------------------
train: {'epoch': 59, 'time_epoch': 421.98834, 'eta': 16988.41485, 'eta_hours': 4.719, 'loss': 0.08581632, 'lr': 0.00019668, 'params': 384641, 'time_iter': 0.50598, 'accuracy': 0.86909, 'precision': 0.58662, 'recall': 0.87487, 'f1': 0.70232, 'auc': 0.94617, 'accuracy-SBM': 0.87136}
val: {'epoch': 59, 'time_epoch': 29.06328, 'loss': 0.08968734, 'lr': 0, 'params': 384641, 'time_iter': 0.17403, 'accuracy': 0.85842, 'precision': 0.56354, 'recall': 0.88778, 'f1': 0.68944, 'auc': 0.94448, 'accuracy-SBM': 0.86994}
test: {'epoch': 59, 'time_epoch': 29.4753, 'loss': 0.0885613, 'lr': 0, 'params': 384641, 'time_iter': 0.1765, 'accuracy': 0.86121, 'precision': 0.56808, 'recall': 0.88616, 'f1': 0.69233, 'auc': 0.94505, 'accuracy-SBM': 0.87101}
> Epoch 59: took 482.1s (avg 485.1s) | Best so far: epoch 57	train_loss: 0.0860 train_accuracy-SBM: 0.8710	val_loss: 0.0889 val_accuracy-SBM: 0.8700	test_loss: 0.0879 test_accuracy-SBM: 0.8709
-----------------------------------------------------------
train: {'epoch': 60, 'time_epoch': 422.06367, 'eta': 16562.01233, 'eta_hours': 4.60056, 'loss': 0.08571584, 'lr': 0.00018863, 'params': 384641, 'time_iter': 0.50607, 'accuracy': 0.86846, 'precision': 0.58506, 'recall': 0.87628, 'f1': 0.70165, 'auc': 0.94627, 'accuracy-SBM': 0.87153}
val: {'epoch': 60, 'time_epoch': 28.94336, 'loss': 0.0884997, 'lr': 0, 'params': 384641, 'time_iter': 0.17331, 'accuracy': 0.86681, 'precision': 0.5825, 'recall': 0.87411, 'f1': 0.69911, 'auc': 0.94414, 'accuracy-SBM': 0.86967}
test: {'epoch': 60, 'time_epoch': 29.34697, 'loss': 0.08748211, 'lr': 0, 'params': 384641, 'time_iter': 0.17573, 'accuracy': 0.86972, 'precision': 0.58766, 'recall': 0.87389, 'f1': 0.70275, 'auc': 0.94478, 'accuracy-SBM': 0.87136}
> Epoch 60: took 481.9s (avg 485.0s) | Best so far: epoch 57	train_loss: 0.0860 train_accuracy-SBM: 0.8710	val_loss: 0.0889 val_accuracy-SBM: 0.8700	test_loss: 0.0879 test_accuracy-SBM: 0.8709
-----------------------------------------------------------
train: {'epoch': 61, 'time_epoch': 422.68308, 'eta': 16136.12941, 'eta_hours': 4.48226, 'loss': 0.08555213, 'lr': 0.00018065, 'params': 384641, 'time_iter': 0.50681, 'accuracy': 0.86879, 'precision': 0.58581, 'recall': 0.87609, 'f1': 0.70213, 'auc': 0.94652, 'accuracy-SBM': 0.87166}
val: {'epoch': 61, 'time_epoch': 29.25574, 'loss': 0.08918624, 'lr': 0, 'params': 384641, 'time_iter': 0.17518, 'accuracy': 0.85115, 'precision': 0.5487, 'recall': 0.89655, 'f1': 0.68076, 'auc': 0.94461, 'accuracy-SBM': 0.86897}
test: {'epoch': 61, 'time_epoch': 29.5733, 'loss': 0.08796967, 'lr': 0, 'params': 384641, 'time_iter': 0.17709, 'accuracy': 0.85397, 'precision': 0.55292, 'recall': 0.89485, 'f1': 0.68351, 'auc': 0.94536, 'accuracy-SBM': 0.87004}
> Epoch 61: took 483.1s (avg 485.0s) | Best so far: epoch 57	train_loss: 0.0860 train_accuracy-SBM: 0.8710	val_loss: 0.0889 val_accuracy-SBM: 0.8700	test_loss: 0.0879 test_accuracy-SBM: 0.8709
-----------------------------------------------------------
train: {'epoch': 62, 'time_epoch': 422.67725, 'eta': 15710.34464, 'eta_hours': 4.36398, 'loss': 0.08544208, 'lr': 0.00017275, 'params': 384641, 'time_iter': 0.50681, 'accuracy': 0.86799, 'precision': 0.58381, 'recall': 0.87813, 'f1': 0.70135, 'auc': 0.94663, 'accuracy-SBM': 0.87197}
val: {'epoch': 62, 'time_epoch': 29.02462, 'loss': 0.08878773, 'lr': 0, 'params': 384641, 'time_iter': 0.1738, 'accuracy': 0.85779, 'precision': 0.56227, 'recall': 0.88783, 'f1': 0.6885, 'auc': 0.94477, 'accuracy-SBM': 0.86958}
test: {'epoch': 62, 'time_epoch': 29.30319, 'loss': 0.08763058, 'lr': 0, 'params': 384641, 'time_iter': 0.17547, 'accuracy': 0.86057, 'precision': 0.56671, 'recall': 0.88673, 'f1': 0.69149, 'auc': 0.94552, 'accuracy-SBM': 0.87085}
> Epoch 62: took 482.6s (avg 484.9s) | Best so far: epoch 57	train_loss: 0.0860 train_accuracy-SBM: 0.8710	val_loss: 0.0889 val_accuracy-SBM: 0.8700	test_loss: 0.0879 test_accuracy-SBM: 0.8709
-----------------------------------------------------------
train: {'epoch': 63, 'time_epoch': 421.76417, 'eta': 15284.14338, 'eta_hours': 4.2456, 'loss': 0.08524761, 'lr': 0.00016493, 'params': 384641, 'time_iter': 0.50571, 'accuracy': 0.8686, 'precision': 0.58524, 'recall': 0.87745, 'f1': 0.70216, 'auc': 0.94688, 'accuracy-SBM': 0.87208}
val: {'epoch': 63, 'time_epoch': 29.07653, 'loss': 0.08890891, 'lr': 0, 'params': 384641, 'time_iter': 0.17411, 'accuracy': 0.86021, 'precision': 0.56736, 'recall': 0.88568, 'f1': 0.69166, 'auc': 0.94465, 'accuracy-SBM': 0.87021}
test: {'epoch': 63, 'time_epoch': 29.40482, 'loss': 0.0877775, 'lr': 0, 'params': 384641, 'time_iter': 0.17608, 'accuracy': 0.86299, 'precision': 0.57201, 'recall': 0.88368, 'f1': 0.69448, 'auc': 0.94531, 'accuracy-SBM': 0.87112}
> Epoch 63: took 481.8s (avg 484.9s) | Best so far: epoch 63	train_loss: 0.0852 train_accuracy-SBM: 0.8721	val_loss: 0.0889 val_accuracy-SBM: 0.8702	test_loss: 0.0878 test_accuracy-SBM: 0.8711
-----------------------------------------------------------
train: {'epoch': 64, 'time_epoch': 421.71673, 'eta': 14858.0531, 'eta_hours': 4.12724, 'loss': 0.08510287, 'lr': 0.0001572, 'params': 384641, 'time_iter': 0.50566, 'accuracy': 0.86888, 'precision': 0.58582, 'recall': 0.87786, 'f1': 0.7027, 'auc': 0.94709, 'accuracy-SBM': 0.87241}
val: {'epoch': 64, 'time_epoch': 29.01189, 'loss': 0.08915345, 'lr': 0, 'params': 384641, 'time_iter': 0.17372, 'accuracy': 0.8601, 'precision': 0.56717, 'recall': 0.8853, 'f1': 0.6914, 'auc': 0.9445, 'accuracy-SBM': 0.86999}
test: {'epoch': 64, 'time_epoch': 29.379, 'loss': 0.08804967, 'lr': 0, 'params': 384641, 'time_iter': 0.17592, 'accuracy': 0.86284, 'precision': 0.57168, 'recall': 0.88392, 'f1': 0.69431, 'auc': 0.94515, 'accuracy-SBM': 0.87113}
> Epoch 64: took 481.7s (avg 484.8s) | Best so far: epoch 63	train_loss: 0.0852 train_accuracy-SBM: 0.8721	val_loss: 0.0889 val_accuracy-SBM: 0.8702	test_loss: 0.0878 test_accuracy-SBM: 0.8711
-----------------------------------------------------------
train: {'epoch': 65, 'time_epoch': 422.36301, 'eta': 14432.42828, 'eta_hours': 4.00901, 'loss': 0.08494898, 'lr': 0.00014958, 'params': 384641, 'time_iter': 0.50643, 'accuracy': 0.86912, 'precision': 0.58629, 'recall': 0.87832, 'f1': 0.70319, 'auc': 0.94726, 'accuracy-SBM': 0.87274}
val: {'epoch': 65, 'time_epoch': 29.11128, 'loss': 0.08874057, 'lr': 0, 'params': 384641, 'time_iter': 0.17432, 'accuracy': 0.85952, 'precision': 0.56595, 'recall': 0.88573, 'f1': 0.69062, 'auc': 0.94479, 'accuracy-SBM': 0.86981}
test: {'epoch': 65, 'time_epoch': 29.26797, 'loss': 0.08765214, 'lr': 0, 'params': 384641, 'time_iter': 0.17526, 'accuracy': 0.86276, 'precision': 0.57136, 'recall': 0.88547, 'f1': 0.69455, 'auc': 0.94546, 'accuracy-SBM': 0.87168}
> Epoch 65: took 482.3s (avg 484.8s) | Best so far: epoch 63	train_loss: 0.0852 train_accuracy-SBM: 0.8721	val_loss: 0.0889 val_accuracy-SBM: 0.8702	test_loss: 0.0878 test_accuracy-SBM: 0.8711
-----------------------------------------------------------
train: {'epoch': 66, 'time_epoch': 421.74798, 'eta': 14006.5979, 'eta_hours': 3.89072, 'loss': 0.08484567, 'lr': 0.00014206, 'params': 384641, 'time_iter': 0.50569, 'accuracy': 0.86891, 'precision': 0.58578, 'recall': 0.8787, 'f1': 0.70294, 'auc': 0.94741, 'accuracy-SBM': 0.87276}
val: {'epoch': 66, 'time_epoch': 29.08131, 'loss': 0.08863149, 'lr': 0, 'params': 384641, 'time_iter': 0.17414, 'accuracy': 0.86772, 'precision': 0.58436, 'recall': 0.87539, 'f1': 0.70086, 'auc': 0.94506, 'accuracy-SBM': 0.87073}
test: {'epoch': 66, 'time_epoch': 29.37442, 'loss': 0.08764235, 'lr': 0, 'params': 384641, 'time_iter': 0.17589, 'accuracy': 0.87103, 'precision': 0.59042, 'recall': 0.87535, 'f1': 0.70519, 'auc': 0.94567, 'accuracy-SBM': 0.87272}
> Epoch 66: took 481.8s (avg 484.8s) | Best so far: epoch 66	train_loss: 0.0848 train_accuracy-SBM: 0.8728	val_loss: 0.0886 val_accuracy-SBM: 0.8707	test_loss: 0.0876 test_accuracy-SBM: 0.8727
-----------------------------------------------------------
train: {'epoch': 67, 'time_epoch': 422.56924, 'eta': 13581.27407, 'eta_hours': 3.77258, 'loss': 0.0846995, 'lr': 0.00013466, 'params': 384641, 'time_iter': 0.50668, 'accuracy': 0.86886, 'precision': 0.58558, 'recall': 0.87958, 'f1': 0.70308, 'auc': 0.94757, 'accuracy-SBM': 0.87307}
val: {'epoch': 67, 'time_epoch': 29.0947, 'loss': 0.08882073, 'lr': 0, 'params': 384641, 'time_iter': 0.17422, 'accuracy': 0.86901, 'precision': 0.5875, 'recall': 0.87301, 'f1': 0.70235, 'auc': 0.94478, 'accuracy-SBM': 0.87058}
test: {'epoch': 67, 'time_epoch': 29.49549, 'loss': 0.08770034, 'lr': 0, 'params': 384641, 'time_iter': 0.17662, 'accuracy': 0.87163, 'precision': 0.59209, 'recall': 0.87299, 'f1': 0.70561, 'auc': 0.94555, 'accuracy-SBM': 0.87217}
> Epoch 67: took 482.7s (avg 484.7s) | Best so far: epoch 66	train_loss: 0.0848 train_accuracy-SBM: 0.8728	val_loss: 0.0886 val_accuracy-SBM: 0.8707	test_loss: 0.0876 test_accuracy-SBM: 0.8727
-----------------------------------------------------------
train: {'epoch': 68, 'time_epoch': 422.14701, 'eta': 13155.84039, 'eta_hours': 3.6544, 'loss': 0.08443788, 'lr': 0.00012739, 'params': 384641, 'time_iter': 0.50617, 'accuracy': 0.86961, 'precision': 0.58728, 'recall': 0.87927, 'f1': 0.7042, 'auc': 0.9479, 'accuracy-SBM': 0.87341}
val: {'epoch': 68, 'time_epoch': 29.0333, 'loss': 0.08916077, 'lr': 0, 'params': 384641, 'time_iter': 0.17385, 'accuracy': 0.87288, 'precision': 0.59737, 'recall': 0.86477, 'f1': 0.70662, 'auc': 0.9444, 'accuracy-SBM': 0.8697}
test: {'epoch': 68, 'time_epoch': 29.41073, 'loss': 0.08808372, 'lr': 0, 'params': 384641, 'time_iter': 0.17611, 'accuracy': 0.87542, 'precision': 0.60201, 'recall': 0.8646, 'f1': 0.7098, 'auc': 0.94522, 'accuracy-SBM': 0.87117}
> Epoch 68: took 482.1s (avg 484.7s) | Best so far: epoch 66	train_loss: 0.0848 train_accuracy-SBM: 0.8728	val_loss: 0.0886 val_accuracy-SBM: 0.8707	test_loss: 0.0876 test_accuracy-SBM: 0.8727
-----------------------------------------------------------
train: {'epoch': 69, 'time_epoch': 422.84672, 'eta': 12730.80049, 'eta_hours': 3.53633, 'loss': 0.08440451, 'lr': 0.00012026, 'params': 384641, 'time_iter': 0.50701, 'accuracy': 0.8697, 'precision': 0.58741, 'recall': 0.87984, 'f1': 0.70448, 'auc': 0.94791, 'accuracy-SBM': 0.87369}
val: {'epoch': 69, 'time_epoch': 29.39079, 'loss': 0.08899049, 'lr': 0, 'params': 384641, 'time_iter': 0.17599, 'accuracy': 0.86267, 'precision': 0.57262, 'recall': 0.88406, 'f1': 0.69505, 'auc': 0.9451, 'accuracy-SBM': 0.87107}
test: {'epoch': 69, 'time_epoch': 29.32057, 'loss': 0.08795314, 'lr': 0, 'params': 384641, 'time_iter': 0.17557, 'accuracy': 0.86519, 'precision': 0.5768, 'recall': 0.88256, 'f1': 0.69765, 'auc': 0.94573, 'accuracy-SBM': 0.87202}
> Epoch 69: took 483.1s (avg 484.7s) | Best so far: epoch 69	train_loss: 0.0844 train_accuracy-SBM: 0.8737	val_loss: 0.0890 val_accuracy-SBM: 0.8711	test_loss: 0.0880 test_accuracy-SBM: 0.8720
-----------------------------------------------------------
train: {'epoch': 70, 'time_epoch': 421.78723, 'eta': 12305.38961, 'eta_hours': 3.41816, 'loss': 0.08424628, 'lr': 0.00011326, 'params': 384641, 'time_iter': 0.50574, 'accuracy': 0.87002, 'precision': 0.58818, 'recall': 0.87919, 'f1': 0.70483, 'auc': 0.94813, 'accuracy-SBM': 0.87362}
val: {'epoch': 70, 'time_epoch': 28.94515, 'loss': 0.08863744, 'lr': 0, 'params': 384641, 'time_iter': 0.17332, 'accuracy': 0.86974, 'precision': 0.58914, 'recall': 0.87294, 'f1': 0.70349, 'auc': 0.94509, 'accuracy-SBM': 0.87099}
test: {'epoch': 70, 'time_epoch': 29.33178, 'loss': 0.08771189, 'lr': 0, 'params': 384641, 'time_iter': 0.17564, 'accuracy': 0.87249, 'precision': 0.59411, 'recall': 0.87258, 'f1': 0.70691, 'auc': 0.94568, 'accuracy-SBM': 0.87253}
> Epoch 70: took 481.6s (avg 484.6s) | Best so far: epoch 69	train_loss: 0.0844 train_accuracy-SBM: 0.8737	val_loss: 0.0890 val_accuracy-SBM: 0.8711	test_loss: 0.0880 test_accuracy-SBM: 0.8720
-----------------------------------------------------------
train: {'epoch': 71, 'time_epoch': 422.25067, 'eta': 11880.25962, 'eta_hours': 3.30007, 'loss': 0.08415756, 'lr': 0.00010642, 'params': 384641, 'time_iter': 0.5063, 'accuracy': 0.87, 'precision': 0.58805, 'recall': 0.87995, 'f1': 0.70498, 'auc': 0.94828, 'accuracy-SBM': 0.87391}
val: {'epoch': 71, 'time_epoch': 29.14361, 'loss': 0.08800755, 'lr': 0, 'params': 384641, 'time_iter': 0.17451, 'accuracy': 0.86698, 'precision': 0.58252, 'recall': 0.87723, 'f1': 0.70013, 'auc': 0.94522, 'accuracy-SBM': 0.871}
test: {'epoch': 71, 'time_epoch': 29.41451, 'loss': 0.08699001, 'lr': 0, 'params': 384641, 'time_iter': 0.17613, 'accuracy': 0.87003, 'precision': 0.58805, 'recall': 0.87632, 'f1': 0.70381, 'auc': 0.94592, 'accuracy-SBM': 0.8725}
> Epoch 71: took 482.4s (avg 484.6s) | Best so far: epoch 69	train_loss: 0.0844 train_accuracy-SBM: 0.8737	val_loss: 0.0890 val_accuracy-SBM: 0.8711	test_loss: 0.0880 test_accuracy-SBM: 0.8720
-----------------------------------------------------------
train: {'epoch': 72, 'time_epoch': 422.75921, 'eta': 11455.39661, 'eta_hours': 3.18205, 'loss': 0.08393362, 'lr': 9.973e-05, 'params': 384641, 'time_iter': 0.50691, 'accuracy': 0.8701, 'precision': 0.58819, 'recall': 0.88076, 'f1': 0.70534, 'auc': 0.9485, 'accuracy-SBM': 0.87429}
val: {'epoch': 72, 'time_epoch': 28.94469, 'loss': 0.08829175, 'lr': 0, 'params': 384641, 'time_iter': 0.17332, 'accuracy': 0.86801, 'precision': 0.58497, 'recall': 0.87561, 'f1': 0.70137, 'auc': 0.94489, 'accuracy-SBM': 0.87099}
test: {'epoch': 72, 'time_epoch': 29.31715, 'loss': 0.08728497, 'lr': 0, 'params': 384641, 'time_iter': 0.17555, 'accuracy': 0.87046, 'precision': 0.5891, 'recall': 0.8757, 'f1': 0.70436, 'auc': 0.94556, 'accuracy-SBM': 0.87252}
> Epoch 72: took 482.6s (avg 484.6s) | Best so far: epoch 69	train_loss: 0.0844 train_accuracy-SBM: 0.8737	val_loss: 0.0890 val_accuracy-SBM: 0.8711	test_loss: 0.0880 test_accuracy-SBM: 0.8720
-----------------------------------------------------------
train: {'epoch': 73, 'time_epoch': 422.2815, 'eta': 11030.42261, 'eta_hours': 3.06401, 'loss': 0.08386572, 'lr': 9.321e-05, 'params': 384641, 'time_iter': 0.50633, 'accuracy': 0.8708, 'precision': 0.58974, 'recall': 0.88076, 'f1': 0.70645, 'auc': 0.94859, 'accuracy-SBM': 0.87471}
val: {'epoch': 73, 'time_epoch': 29.25145, 'loss': 0.08889724, 'lr': 0, 'params': 384641, 'time_iter': 0.17516, 'accuracy': 0.87575, 'precision': 0.60447, 'recall': 0.86236, 'f1': 0.71075, 'auc': 0.94518, 'accuracy-SBM': 0.87049}
test: {'epoch': 73, 'time_epoch': 29.48559, 'loss': 0.08804604, 'lr': 0, 'params': 384641, 'time_iter': 0.17656, 'accuracy': 0.87834, 'precision': 0.6093, 'recall': 0.86301, 'f1': 0.71429, 'auc': 0.94574, 'accuracy-SBM': 0.87231}
> Epoch 73: took 482.6s (avg 484.5s) | Best so far: epoch 69	train_loss: 0.0844 train_accuracy-SBM: 0.8737	val_loss: 0.0890 val_accuracy-SBM: 0.8711	test_loss: 0.0880 test_accuracy-SBM: 0.8720
-----------------------------------------------------------
train: {'epoch': 74, 'time_epoch': 422.21903, 'eta': 10605.49959, 'eta_hours': 2.94597, 'loss': 0.08377525, 'lr': 8.685e-05, 'params': 384641, 'time_iter': 0.50626, 'accuracy': 0.87053, 'precision': 0.58911, 'recall': 0.88099, 'f1': 0.70607, 'auc': 0.94874, 'accuracy-SBM': 0.87464}
val: {'epoch': 74, 'time_epoch': 28.94685, 'loss': 0.08850161, 'lr': 0, 'params': 384641, 'time_iter': 0.17333, 'accuracy': 0.8722, 'precision': 0.59515, 'recall': 0.86951, 'f1': 0.70664, 'auc': 0.94519, 'accuracy-SBM': 0.87114}
test: {'epoch': 74, 'time_epoch': 29.42662, 'loss': 0.08746929, 'lr': 0, 'params': 384641, 'time_iter': 0.17621, 'accuracy': 0.87499, 'precision': 0.60039, 'recall': 0.86906, 'f1': 0.71016, 'auc': 0.94583, 'accuracy-SBM': 0.87266}
> Epoch 74: took 482.1s (avg 484.5s) | Best so far: epoch 74	train_loss: 0.0838 train_accuracy-SBM: 0.8746	val_loss: 0.0885 val_accuracy-SBM: 0.8711	test_loss: 0.0875 test_accuracy-SBM: 0.8727
-----------------------------------------------------------
train: {'epoch': 75, 'time_epoch': 421.64753, 'eta': 10180.46725, 'eta_hours': 2.82791, 'loss': 0.08371369, 'lr': 8.068e-05, 'params': 384641, 'time_iter': 0.50557, 'accuracy': 0.87083, 'precision': 0.58985, 'recall': 0.88041, 'f1': 0.70642, 'auc': 0.9488, 'accuracy-SBM': 0.87459}
val: {'epoch': 75, 'time_epoch': 29.09053, 'loss': 0.08846522, 'lr': 0, 'params': 384641, 'time_iter': 0.17419, 'accuracy': 0.86543, 'precision': 0.57884, 'recall': 0.88037, 'f1': 0.69845, 'auc': 0.94514, 'accuracy-SBM': 0.8713}
test: {'epoch': 75, 'time_epoch': 29.32774, 'loss': 0.08735832, 'lr': 0, 'params': 384641, 'time_iter': 0.17562, 'accuracy': 0.86865, 'precision': 0.58463, 'recall': 0.87935, 'f1': 0.70233, 'auc': 0.94591, 'accuracy-SBM': 0.87285}
> Epoch 75: took 481.6s (avg 484.5s) | Best so far: epoch 75	train_loss: 0.0837 train_accuracy-SBM: 0.8746	val_loss: 0.0885 val_accuracy-SBM: 0.8713	test_loss: 0.0874 test_accuracy-SBM: 0.8729
-----------------------------------------------------------
train: {'epoch': 76, 'time_epoch': 422.27053, 'eta': 9755.70892, 'eta_hours': 2.70992, 'loss': 0.08352579, 'lr': 7.469e-05, 'params': 384641, 'time_iter': 0.50632, 'accuracy': 0.87038, 'precision': 0.58866, 'recall': 0.88189, 'f1': 0.70604, 'auc': 0.94904, 'accuracy-SBM': 0.8749}
val: {'epoch': 76, 'time_epoch': 29.03746, 'loss': 0.08888364, 'lr': 0, 'params': 384641, 'time_iter': 0.17388, 'accuracy': 0.85763, 'precision': 0.56169, 'recall': 0.89114, 'f1': 0.68906, 'auc': 0.94528, 'accuracy-SBM': 0.87078}
test: {'epoch': 76, 'time_epoch': 29.30196, 'loss': 0.08778434, 'lr': 0, 'params': 384641, 'time_iter': 0.17546, 'accuracy': 0.86066, 'precision': 0.56662, 'recall': 0.88995, 'f1': 0.6924, 'auc': 0.94587, 'accuracy-SBM': 0.87217}
> Epoch 76: took 482.2s (avg 484.4s) | Best so far: epoch 75	train_loss: 0.0837 train_accuracy-SBM: 0.8746	val_loss: 0.0885 val_accuracy-SBM: 0.8713	test_loss: 0.0874 test_accuracy-SBM: 0.8729
-----------------------------------------------------------
train: {'epoch': 77, 'time_epoch': 422.05594, 'eta': 9330.95386, 'eta_hours': 2.59193, 'loss': 0.08340484, 'lr': 6.889e-05, 'params': 384641, 'time_iter': 0.50606, 'accuracy': 0.87087, 'precision': 0.58981, 'recall': 0.88151, 'f1': 0.70675, 'auc': 0.94919, 'accuracy-SBM': 0.87505}
val: {'epoch': 77, 'time_epoch': 29.24847, 'loss': 0.08841825, 'lr': 0, 'params': 384641, 'time_iter': 0.17514, 'accuracy': 0.86319, 'precision': 0.57377, 'recall': 0.88333, 'f1': 0.69566, 'auc': 0.94516, 'accuracy-SBM': 0.87109}
test: {'epoch': 77, 'time_epoch': 29.38534, 'loss': 0.08740169, 'lr': 0, 'params': 384641, 'time_iter': 0.17596, 'accuracy': 0.86628, 'precision': 0.57913, 'recall': 0.88254, 'f1': 0.69935, 'auc': 0.94576, 'accuracy-SBM': 0.87267}
> Epoch 77: took 482.2s (avg 484.4s) | Best so far: epoch 75	train_loss: 0.0837 train_accuracy-SBM: 0.8746	val_loss: 0.0885 val_accuracy-SBM: 0.8713	test_loss: 0.0874 test_accuracy-SBM: 0.8729
-----------------------------------------------------------
train: {'epoch': 78, 'time_epoch': 422.28203, 'eta': 8906.32723, 'eta_hours': 2.47398, 'loss': 0.083417, 'lr': 6.329e-05, 'params': 384641, 'time_iter': 0.50633, 'accuracy': 0.87063, 'precision': 0.58924, 'recall': 0.88176, 'f1': 0.70642, 'auc': 0.94915, 'accuracy-SBM': 0.875}
val: {'epoch': 78, 'time_epoch': 29.00966, 'loss': 0.08820432, 'lr': 0, 'params': 384641, 'time_iter': 0.17371, 'accuracy': 0.86671, 'precision': 0.58183, 'recall': 0.87825, 'f1': 0.69995, 'auc': 0.94528, 'accuracy-SBM': 0.87124}
test: {'epoch': 78, 'time_epoch': 29.39681, 'loss': 0.08726208, 'lr': 0, 'params': 384641, 'time_iter': 0.17603, 'accuracy': 0.86999, 'precision': 0.58774, 'recall': 0.87835, 'f1': 0.70424, 'auc': 0.94586, 'accuracy-SBM': 0.87328}
> Epoch 78: took 482.2s (avg 484.4s) | Best so far: epoch 75	train_loss: 0.0837 train_accuracy-SBM: 0.8746	val_loss: 0.0885 val_accuracy-SBM: 0.8713	test_loss: 0.0874 test_accuracy-SBM: 0.8729
-----------------------------------------------------------
train: {'epoch': 79, 'time_epoch': 421.97098, 'eta': 8481.68144, 'eta_hours': 2.35602, 'loss': 0.08316947, 'lr': 5.79e-05, 'params': 384641, 'time_iter': 0.50596, 'accuracy': 0.87088, 'precision': 0.5897, 'recall': 0.88261, 'f1': 0.70702, 'auc': 0.94947, 'accuracy-SBM': 0.87549}
val: {'epoch': 79, 'time_epoch': 28.97389, 'loss': 0.08825746, 'lr': 0, 'params': 384641, 'time_iter': 0.1735, 'accuracy': 0.86511, 'precision': 0.57811, 'recall': 0.88071, 'f1': 0.69803, 'auc': 0.94533, 'accuracy-SBM': 0.87123}
test: {'epoch': 79, 'time_epoch': 29.29958, 'loss': 0.08725463, 'lr': 0, 'params': 384641, 'time_iter': 0.17545, 'accuracy': 0.86847, 'precision': 0.58411, 'recall': 0.88061, 'f1': 0.70235, 'auc': 0.94595, 'accuracy-SBM': 0.87324}
> Epoch 79: took 481.8s (avg 484.4s) | Best so far: epoch 75	train_loss: 0.0837 train_accuracy-SBM: 0.8746	val_loss: 0.0885 val_accuracy-SBM: 0.8713	test_loss: 0.0874 test_accuracy-SBM: 0.8729
-----------------------------------------------------------
train: {'epoch': 80, 'time_epoch': 422.14447, 'eta': 8057.1424, 'eta_hours': 2.2381, 'loss': 0.08311185, 'lr': 5.271e-05, 'params': 384641, 'time_iter': 0.50617, 'accuracy': 0.87107, 'precision': 0.59019, 'recall': 0.88209, 'f1': 0.7072, 'auc': 0.94955, 'accuracy-SBM': 0.8754}
val: {'epoch': 80, 'time_epoch': 29.1605, 'loss': 0.08841783, 'lr': 0, 'params': 384641, 'time_iter': 0.17461, 'accuracy': 0.86997, 'precision': 0.58957, 'recall': 0.87373, 'f1': 0.70406, 'auc': 0.94536, 'accuracy-SBM': 0.87145}
test: {'epoch': 80, 'time_epoch': 29.4172, 'loss': 0.08745627, 'lr': 0, 'params': 384641, 'time_iter': 0.17615, 'accuracy': 0.8735, 'precision': 0.59631, 'recall': 0.87346, 'f1': 0.70875, 'auc': 0.94599, 'accuracy-SBM': 0.87348}
> Epoch 80: took 482.3s (avg 484.3s) | Best so far: epoch 80	train_loss: 0.0831 train_accuracy-SBM: 0.8754	val_loss: 0.0884 val_accuracy-SBM: 0.8714	test_loss: 0.0875 test_accuracy-SBM: 0.8735
-----------------------------------------------------------
train: {'epoch': 81, 'time_epoch': 422.36762, 'eta': 7632.71075, 'eta_hours': 2.1202, 'loss': 0.08301512, 'lr': 4.775e-05, 'params': 384641, 'time_iter': 0.50644, 'accuracy': 0.87076, 'precision': 0.58937, 'recall': 0.88318, 'f1': 0.70696, 'auc': 0.94967, 'accuracy-SBM': 0.87564}
val: {'epoch': 81, 'time_epoch': 29.34275, 'loss': 0.08836246, 'lr': 0, 'params': 384641, 'time_iter': 0.17571, 'accuracy': 0.86827, 'precision': 0.58551, 'recall': 0.87592, 'f1': 0.70186, 'auc': 0.94515, 'accuracy-SBM': 0.87127}
test: {'epoch': 81, 'time_epoch': 29.3597, 'loss': 0.08745195, 'lr': 0, 'params': 384641, 'time_iter': 0.17581, 'accuracy': 0.87127, 'precision': 0.59098, 'recall': 0.8753, 'f1': 0.70558, 'auc': 0.94573, 'accuracy-SBM': 0.87285}
> Epoch 81: took 482.6s (avg 484.3s) | Best so far: epoch 80	train_loss: 0.0831 train_accuracy-SBM: 0.8754	val_loss: 0.0884 val_accuracy-SBM: 0.8714	test_loss: 0.0875 test_accuracy-SBM: 0.8735
-----------------------------------------------------------
train: {'epoch': 82, 'time_epoch': 422.49002, 'eta': 7208.3539, 'eta_hours': 2.00232, 'loss': 0.08294398, 'lr': 4.3e-05, 'params': 384641, 'time_iter': 0.50658, 'accuracy': 0.87134, 'precision': 0.59072, 'recall': 0.88274, 'f1': 0.70779, 'auc': 0.94973, 'accuracy-SBM': 0.87582}
val: {'epoch': 82, 'time_epoch': 29.12818, 'loss': 0.08853494, 'lr': 0, 'params': 384641, 'time_iter': 0.17442, 'accuracy': 0.86609, 'precision': 0.58041, 'recall': 0.87887, 'f1': 0.69912, 'auc': 0.94522, 'accuracy-SBM': 0.8711}
test: {'epoch': 82, 'time_epoch': 29.41239, 'loss': 0.0875123, 'lr': 0, 'params': 384641, 'time_iter': 0.17612, 'accuracy': 0.86964, 'precision': 0.58692, 'recall': 0.87863, 'f1': 0.70374, 'auc': 0.94591, 'accuracy-SBM': 0.87317}
> Epoch 82: took 482.6s (avg 484.3s) | Best so far: epoch 80	train_loss: 0.0831 train_accuracy-SBM: 0.8754	val_loss: 0.0884 val_accuracy-SBM: 0.8714	test_loss: 0.0875 test_accuracy-SBM: 0.8735
-----------------------------------------------------------
train: {'epoch': 83, 'time_epoch': 422.63053, 'eta': 6784.06827, 'eta_hours': 1.88446, 'loss': 0.08283492, 'lr': 3.848e-05, 'params': 384641, 'time_iter': 0.50675, 'accuracy': 0.87098, 'precision': 0.58982, 'recall': 0.88355, 'f1': 0.7074, 'auc': 0.94988, 'accuracy-SBM': 0.87592}
val: {'epoch': 83, 'time_epoch': 29.05011, 'loss': 0.08842234, 'lr': 0, 'params': 384641, 'time_iter': 0.17395, 'accuracy': 0.86469, 'precision': 0.57724, 'recall': 0.88049, 'f1': 0.69732, 'auc': 0.94534, 'accuracy-SBM': 0.87089}
test: {'epoch': 83, 'time_epoch': 29.33969, 'loss': 0.08744514, 'lr': 0, 'params': 384641, 'time_iter': 0.17569, 'accuracy': 0.86867, 'precision': 0.58459, 'recall': 0.88023, 'f1': 0.70258, 'auc': 0.94596, 'accuracy-SBM': 0.87321}
> Epoch 83: took 482.6s (avg 484.3s) | Best so far: epoch 80	train_loss: 0.0831 train_accuracy-SBM: 0.8754	val_loss: 0.0884 val_accuracy-SBM: 0.8714	test_loss: 0.0875 test_accuracy-SBM: 0.8735
-----------------------------------------------------------
train: {'epoch': 84, 'time_epoch': 422.51139, 'eta': 6359.80055, 'eta_hours': 1.76661, 'loss': 0.08267956, 'lr': 3.419e-05, 'params': 384641, 'time_iter': 0.50661, 'accuracy': 0.871, 'precision': 0.58984, 'recall': 0.88371, 'f1': 0.70747, 'auc': 0.95002, 'accuracy-SBM': 0.87599}
val: {'epoch': 84, 'time_epoch': 29.13122, 'loss': 0.0886284, 'lr': 0, 'params': 384641, 'time_iter': 0.17444, 'accuracy': 0.86398, 'precision': 0.57562, 'recall': 0.88147, 'f1': 0.69645, 'auc': 0.94515, 'accuracy-SBM': 0.87084}
test: {'epoch': 84, 'time_epoch': 29.46603, 'loss': 0.08755551, 'lr': 0, 'params': 384641, 'time_iter': 0.17644, 'accuracy': 0.86758, 'precision': 0.58211, 'recall': 0.88104, 'f1': 0.70104, 'auc': 0.94584, 'accuracy-SBM': 0.87287}
> Epoch 84: took 482.7s (avg 484.2s) | Best so far: epoch 80	train_loss: 0.0831 train_accuracy-SBM: 0.8754	val_loss: 0.0884 val_accuracy-SBM: 0.8714	test_loss: 0.0875 test_accuracy-SBM: 0.8735
-----------------------------------------------------------
train: {'epoch': 85, 'time_epoch': 422.86562, 'eta': 5935.63135, 'eta_hours': 1.64879, 'loss': 0.08260588, 'lr': 3.013e-05, 'params': 384641, 'time_iter': 0.50703, 'accuracy': 0.87152, 'precision': 0.59102, 'recall': 0.88363, 'f1': 0.70829, 'auc': 0.95017, 'accuracy-SBM': 0.87628}
val: {'epoch': 85, 'time_epoch': 29.13344, 'loss': 0.08860671, 'lr': 0, 'params': 384641, 'time_iter': 0.17445, 'accuracy': 0.87128, 'precision': 0.59275, 'recall': 0.87192, 'f1': 0.70573, 'auc': 0.94527, 'accuracy-SBM': 0.87153}
test: {'epoch': 85, 'time_epoch': 29.46476, 'loss': 0.08772097, 'lr': 0, 'params': 384641, 'time_iter': 0.17644, 'accuracy': 0.87397, 'precision': 0.59779, 'recall': 0.87053, 'f1': 0.70883, 'auc': 0.94583, 'accuracy-SBM': 0.87262}
> Epoch 85: took 483.0s (avg 484.2s) | Best so far: epoch 85	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0886 val_accuracy-SBM: 0.8715	test_loss: 0.0877 test_accuracy-SBM: 0.8726
-----------------------------------------------------------
train: {'epoch': 86, 'time_epoch': 422.62318, 'eta': 5511.45588, 'eta_hours': 1.53096, 'loss': 0.08261086, 'lr': 2.632e-05, 'params': 384641, 'time_iter': 0.50674, 'accuracy': 0.87143, 'precision': 0.59079, 'recall': 0.88384, 'f1': 0.70819, 'auc': 0.95009, 'accuracy-SBM': 0.87631}
val: {'epoch': 86, 'time_epoch': 29.27113, 'loss': 0.0884514, 'lr': 0, 'params': 384641, 'time_iter': 0.17528, 'accuracy': 0.87032, 'precision': 0.59033, 'recall': 0.87392, 'f1': 0.70466, 'auc': 0.94543, 'accuracy-SBM': 0.87173}
test: {'epoch': 86, 'time_epoch': 29.40134, 'loss': 0.08755828, 'lr': 0, 'params': 384641, 'time_iter': 0.17606, 'accuracy': 0.87336, 'precision': 0.59606, 'recall': 0.87284, 'f1': 0.70837, 'auc': 0.94597, 'accuracy-SBM': 0.87315}
> Epoch 86: took 482.8s (avg 484.2s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 87, 'time_epoch': 423.04263, 'eta': 5087.3729, 'eta_hours': 1.41316, 'loss': 0.08247331, 'lr': 2.275e-05, 'params': 384641, 'time_iter': 0.50725, 'accuracy': 0.87207, 'precision': 0.59215, 'recall': 0.88442, 'f1': 0.70936, 'auc': 0.95035, 'accuracy-SBM': 0.87692}
val: {'epoch': 87, 'time_epoch': 29.24569, 'loss': 0.08862764, 'lr': 0, 'params': 384641, 'time_iter': 0.17512, 'accuracy': 0.86479, 'precision': 0.57735, 'recall': 0.88144, 'f1': 0.6977, 'auc': 0.94533, 'accuracy-SBM': 0.87132}
test: {'epoch': 87, 'time_epoch': 29.4159, 'loss': 0.08767429, 'lr': 0, 'params': 384641, 'time_iter': 0.17614, 'accuracy': 0.86849, 'precision': 0.58419, 'recall': 0.8803, 'f1': 0.70231, 'auc': 0.94591, 'accuracy-SBM': 0.87313}
> Epoch 87: took 483.3s (avg 484.2s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 88, 'time_epoch': 422.13372, 'eta': 4663.20095, 'eta_hours': 1.29533, 'loss': 0.08245137, 'lr': 1.943e-05, 'params': 384641, 'time_iter': 0.50616, 'accuracy': 0.87156, 'precision': 0.59097, 'recall': 0.88468, 'f1': 0.70859, 'auc': 0.95034, 'accuracy-SBM': 0.87671}
val: {'epoch': 88, 'time_epoch': 29.13983, 'loss': 0.08841585, 'lr': 0, 'params': 384641, 'time_iter': 0.17449, 'accuracy': 0.86472, 'precision': 0.57718, 'recall': 0.88171, 'f1': 0.69766, 'auc': 0.94533, 'accuracy-SBM': 0.87139}
test: {'epoch': 88, 'time_epoch': 29.70117, 'loss': 0.08742936, 'lr': 0, 'params': 384641, 'time_iter': 0.17785, 'accuracy': 0.868, 'precision': 0.58311, 'recall': 0.8804, 'f1': 0.70156, 'auc': 0.94591, 'accuracy-SBM': 0.87287}
> Epoch 88: took 482.5s (avg 484.2s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 89, 'time_epoch': 422.06433, 'eta': 4239.06659, 'eta_hours': 1.17752, 'loss': 0.08234155, 'lr': 1.636e-05, 'params': 384641, 'time_iter': 0.50607, 'accuracy': 0.87211, 'precision': 0.59219, 'recall': 0.88476, 'f1': 0.7095, 'auc': 0.95048, 'accuracy-SBM': 0.87708}
val: {'epoch': 89, 'time_epoch': 29.09834, 'loss': 0.08856705, 'lr': 0, 'params': 384641, 'time_iter': 0.17424, 'accuracy': 0.86381, 'precision': 0.57516, 'recall': 0.88261, 'f1': 0.69647, 'auc': 0.94535, 'accuracy-SBM': 0.87119}
test: {'epoch': 89, 'time_epoch': 29.49738, 'loss': 0.08757056, 'lr': 0, 'params': 384641, 'time_iter': 0.17663, 'accuracy': 0.86749, 'precision': 0.58186, 'recall': 0.88154, 'f1': 0.70102, 'auc': 0.94593, 'accuracy-SBM': 0.87301}
> Epoch 89: took 482.2s (avg 484.2s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 90, 'time_epoch': 422.66152, 'eta': 3815.03678, 'eta_hours': 1.05973, 'loss': 0.08235063, 'lr': 1.355e-05, 'params': 384641, 'time_iter': 0.50679, 'accuracy': 0.87159, 'precision': 0.59097, 'recall': 0.88523, 'f1': 0.70877, 'auc': 0.95042, 'accuracy-SBM': 0.87695}
val: {'epoch': 90, 'time_epoch': 29.20735, 'loss': 0.08842339, 'lr': 0, 'params': 384641, 'time_iter': 0.17489, 'accuracy': 0.86488, 'precision': 0.57754, 'recall': 0.88144, 'f1': 0.69784, 'auc': 0.94535, 'accuracy-SBM': 0.87138}
test: {'epoch': 90, 'time_epoch': 29.50744, 'loss': 0.08749292, 'lr': 0, 'params': 384641, 'time_iter': 0.17669, 'accuracy': 0.86788, 'precision': 0.58279, 'recall': 0.8808, 'f1': 0.70145, 'auc': 0.9459, 'accuracy-SBM': 0.87296}
> Epoch 90: took 482.9s (avg 484.1s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 91, 'time_epoch': 422.28651, 'eta': 3391.00411, 'eta_hours': 0.94195, 'loss': 0.08232028, 'lr': 1.099e-05, 'params': 384641, 'time_iter': 0.50634, 'accuracy': 0.87169, 'precision': 0.59123, 'recall': 0.88488, 'f1': 0.70885, 'auc': 0.9505, 'accuracy-SBM': 0.87687}
val: {'epoch': 91, 'time_epoch': 29.23335, 'loss': 0.08838902, 'lr': 0, 'params': 384641, 'time_iter': 0.17505, 'accuracy': 0.86728, 'precision': 0.58308, 'recall': 0.87808, 'f1': 0.70081, 'auc': 0.94532, 'accuracy-SBM': 0.87152}
test: {'epoch': 91, 'time_epoch': 29.36954, 'loss': 0.0875125, 'lr': 0, 'params': 384641, 'time_iter': 0.17587, 'accuracy': 0.87046, 'precision': 0.58895, 'recall': 0.87697, 'f1': 0.70466, 'auc': 0.94587, 'accuracy-SBM': 0.87302}
> Epoch 91: took 482.4s (avg 484.1s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 92, 'time_epoch': 422.55726, 'eta': 2967.02938, 'eta_hours': 0.82417, 'loss': 0.08228462, 'lr': 8.7e-06, 'params': 384641, 'time_iter': 0.50666, 'accuracy': 0.87163, 'precision': 0.59107, 'recall': 0.88504, 'f1': 0.70878, 'auc': 0.95051, 'accuracy-SBM': 0.8769}
val: {'epoch': 92, 'time_epoch': 29.04526, 'loss': 0.0885921, 'lr': 0, 'params': 384641, 'time_iter': 0.17392, 'accuracy': 0.86655, 'precision': 0.58141, 'recall': 0.87882, 'f1': 0.69983, 'auc': 0.94533, 'accuracy-SBM': 0.87136}
test: {'epoch': 92, 'time_epoch': 29.5453, 'loss': 0.08761395, 'lr': 0, 'params': 384641, 'time_iter': 0.17692, 'accuracy': 0.87021, 'precision': 0.58827, 'recall': 0.87801, 'f1': 0.70451, 'auc': 0.94593, 'accuracy-SBM': 0.87328}
> Epoch 92: took 482.7s (avg 484.1s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 93, 'time_epoch': 422.57249, 'eta': 2543.08577, 'eta_hours': 0.70641, 'loss': 0.08226184, 'lr': 6.67e-06, 'params': 384641, 'time_iter': 0.50668, 'accuracy': 0.87193, 'precision': 0.59172, 'recall': 0.88534, 'f1': 0.70935, 'auc': 0.95059, 'accuracy-SBM': 0.8772}
val: {'epoch': 93, 'time_epoch': 29.06323, 'loss': 0.08852794, 'lr': 0, 'params': 384641, 'time_iter': 0.17403, 'accuracy': 0.86596, 'precision': 0.58004, 'recall': 0.87968, 'f1': 0.69911, 'auc': 0.94527, 'accuracy-SBM': 0.87134}
test: {'epoch': 93, 'time_epoch': 29.27004, 'loss': 0.08758257, 'lr': 0, 'params': 384641, 'time_iter': 0.17527, 'accuracy': 0.86935, 'precision': 0.58626, 'recall': 0.87866, 'f1': 0.70328, 'auc': 0.94585, 'accuracy-SBM': 0.87301}
> Epoch 93: took 482.4s (avg 484.1s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 94, 'time_epoch': 422.64473, 'eta': 2119.17483, 'eta_hours': 0.58866, 'loss': 0.082291, 'lr': 4.91e-06, 'params': 384641, 'time_iter': 0.50677, 'accuracy': 0.87143, 'precision': 0.59067, 'recall': 0.88479, 'f1': 0.70842, 'auc': 0.95052, 'accuracy-SBM': 0.87668}
val: {'epoch': 94, 'time_epoch': 28.97924, 'loss': 0.08854667, 'lr': 0, 'params': 384641, 'time_iter': 0.17353, 'accuracy': 0.86793, 'precision': 0.58476, 'recall': 0.87604, 'f1': 0.70136, 'auc': 0.94518, 'accuracy-SBM': 0.87111}
test: {'epoch': 94, 'time_epoch': 29.38638, 'loss': 0.08763037, 'lr': 0, 'params': 384641, 'time_iter': 0.17597, 'accuracy': 0.87139, 'precision': 0.59119, 'recall': 0.87582, 'f1': 0.70589, 'auc': 0.94577, 'accuracy-SBM': 0.87313}
> Epoch 94: took 482.6s (avg 484.1s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 95, 'time_epoch': 422.12722, 'eta': 1695.26871, 'eta_hours': 0.47091, 'loss': 0.08224931, 'lr': 3.41e-06, 'params': 384641, 'time_iter': 0.50615, 'accuracy': 0.87177, 'precision': 0.5914, 'recall': 0.8851, 'f1': 0.70904, 'auc': 0.95055, 'accuracy-SBM': 0.87701}
val: {'epoch': 95, 'time_epoch': 29.1168, 'loss': 0.08847149, 'lr': 0, 'params': 384641, 'time_iter': 0.17435, 'accuracy': 0.86467, 'precision': 0.5771, 'recall': 0.88142, 'f1': 0.69751, 'auc': 0.94535, 'accuracy-SBM': 0.87124}
test: {'epoch': 95, 'time_epoch': 29.32423, 'loss': 0.08746101, 'lr': 0, 'params': 384641, 'time_iter': 0.17559, 'accuracy': 0.8682, 'precision': 0.58349, 'recall': 0.88094, 'f1': 0.70201, 'auc': 0.94599, 'accuracy-SBM': 0.87321}
> Epoch 95: took 482.1s (avg 484.1s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 96, 'time_epoch': 422.23267, 'eta': 1271.40253, 'eta_hours': 0.35317, 'loss': 0.08224619, 'lr': 2.18e-06, 'params': 384641, 'time_iter': 0.50627, 'accuracy': 0.87223, 'precision': 0.59241, 'recall': 0.88515, 'f1': 0.70978, 'auc': 0.95055, 'accuracy-SBM': 0.8773}
val: {'epoch': 96, 'time_epoch': 29.0095, 'loss': 0.08861299, 'lr': 0, 'params': 384641, 'time_iter': 0.17371, 'accuracy': 0.86534, 'precision': 0.57865, 'recall': 0.88037, 'f1': 0.69832, 'auc': 0.94525, 'accuracy-SBM': 0.87124}
test: {'epoch': 96, 'time_epoch': 29.55808, 'loss': 0.08760464, 'lr': 0, 'params': 384641, 'time_iter': 0.17699, 'accuracy': 0.86898, 'precision': 0.58526, 'recall': 0.88025, 'f1': 0.70307, 'auc': 0.94585, 'accuracy-SBM': 0.87341}
> Epoch 96: took 482.4s (avg 484.0s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 97, 'time_epoch': 422.65828, 'eta': 847.57837, 'eta_hours': 0.23544, 'loss': 0.08217395, 'lr': 1.23e-06, 'params': 384641, 'time_iter': 0.50678, 'accuracy': 0.87221, 'precision': 0.59237, 'recall': 0.88516, 'f1': 0.70976, 'auc': 0.95068, 'accuracy-SBM': 0.8773}
val: {'epoch': 97, 'time_epoch': 29.17086, 'loss': 0.08847231, 'lr': 0, 'params': 384641, 'time_iter': 0.17468, 'accuracy': 0.86855, 'precision': 0.58614, 'recall': 0.87585, 'f1': 0.70229, 'auc': 0.94517, 'accuracy-SBM': 0.87141}
test: {'epoch': 97, 'time_epoch': 29.46736, 'loss': 0.08757284, 'lr': 0, 'params': 384641, 'time_iter': 0.17645, 'accuracy': 0.87163, 'precision': 0.59181, 'recall': 0.8752, 'f1': 0.70614, 'auc': 0.94575, 'accuracy-SBM': 0.87304}
> Epoch 97: took 482.9s (avg 484.0s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 98, 'time_epoch': 422.45189, 'eta': 423.77568, 'eta_hours': 0.11772, 'loss': 0.08220352, 'lr': 5.5e-07, 'params': 384641, 'time_iter': 0.50654, 'accuracy': 0.87187, 'precision': 0.59169, 'recall': 0.88444, 'f1': 0.70904, 'auc': 0.95064, 'accuracy-SBM': 0.87681}
val: {'epoch': 98, 'time_epoch': 29.20529, 'loss': 0.08858618, 'lr': 0, 'params': 384641, 'time_iter': 0.17488, 'accuracy': 0.86557, 'precision': 0.57914, 'recall': 0.8804, 'f1': 0.69868, 'auc': 0.94528, 'accuracy-SBM': 0.87139}
test: {'epoch': 98, 'time_epoch': 29.51545, 'loss': 0.08762903, 'lr': 0, 'params': 384641, 'time_iter': 0.17674, 'accuracy': 0.86889, 'precision': 0.58516, 'recall': 0.87944, 'f1': 0.70274, 'auc': 0.94587, 'accuracy-SBM': 0.87304}
> Epoch 98: took 482.7s (avg 484.0s) | Best so far: epoch 86	train_loss: 0.0826 train_accuracy-SBM: 0.8763	val_loss: 0.0885 val_accuracy-SBM: 0.8717	test_loss: 0.0876 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
train: {'epoch': 99, 'time_epoch': 422.07377, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.08216645, 'lr': 1.4e-07, 'params': 384641, 'time_iter': 0.50608, 'accuracy': 0.8722, 'precision': 0.59244, 'recall': 0.88435, 'f1': 0.70954, 'auc': 0.95071, 'accuracy-SBM': 0.87697}
val: {'epoch': 99, 'time_epoch': 28.98931, 'loss': 0.08877671, 'lr': 0, 'params': 384641, 'time_iter': 0.17359, 'accuracy': 0.87256, 'precision': 0.59585, 'recall': 0.87049, 'f1': 0.70745, 'auc': 0.94515, 'accuracy-SBM': 0.87174}
test: {'epoch': 99, 'time_epoch': 29.4414, 'loss': 0.08787549, 'lr': 0, 'params': 384641, 'time_iter': 0.1763, 'accuracy': 0.87556, 'precision': 0.6017, 'recall': 0.86927, 'f1': 0.71115, 'auc': 0.94577, 'accuracy-SBM': 0.87309}
> Epoch 99: took 482.1s (avg 484.0s) | Best so far: epoch 99	train_loss: 0.0822 train_accuracy-SBM: 0.8770	val_loss: 0.0888 val_accuracy-SBM: 0.8717	test_loss: 0.0879 test_accuracy-SBM: 0.8731
-----------------------------------------------------------
Avg time per epoch: 484.00s
Total train loop time: 13.44h
Task done, results saved in results/pattern-GRIT-RRWP/0
Results aggregated across runs saved in results/pattern-GRIT-RRWP/agg
[*] All done: 2023-11-11 07:14:06.625876
